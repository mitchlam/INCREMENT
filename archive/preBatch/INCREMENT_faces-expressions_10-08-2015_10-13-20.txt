./incDriver.py data/faces-expressions.csv -k 4 -I -T -v 1


Using: data/faces-expressions.csv (624)  --  (4.889642 s)
Initial Clustering: kmeans
Initial:  --  (1.587217 s)
Accuracy: 164 of 624: 26.282 %
H: 0.000780 C: 0.000815 V: 0.000797 JCC: 0.150311

Rows are labels, Columns are Clusters

      0   1   2   3
  0  28  37  27  66
  1  25  37  31  63
  2  28  34  31  62
  3  30  37  28  60




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 2.857645 (111)
		0: 2.876661 -- 1.588256  (8)
		1: 1.537218 -- 0.911748  (4)
		2: 3.046473 -- 1.975313  (10)
		3: 3.508395 -- 1.844449  (8)
		4: 2.811077 -- 0.863014  (18)
		5: 2.968336 -- 1.133865  (8)
		6: 2.169191 -- 1.703185  (6)
		7: 4.034521 -- 3.116190  (7)
		8: 3.173649 -- 1.268235  (9)
		9: 3.132841 -- 1.376396  (7)
		10: 2.363704 -- 0.966322  (7)
		11: 3.018032 -- 2.079177  (9)
		12: 0.857896 -- 0.496648  (4)
		13: 2.711523 -- 1.310457  (6)
	--> std: 1.714201 -- 0.633237

	1: 2.822577 (145)
		14: 2.426341 -- 1.607920  (8)
		15: 2.998473 -- 1.106252  (10)
		16: 1.141513 -- 0.741818  (8)
		17: 1.077569 -- 0.622549  (4)
		18: 2.342634 -- 0.919699  (14)
		19: 2.836205 -- 0.997558  (11)
		20: 2.798881 -- 1.820396  (5)
		21: 3.611614 -- 1.882524  (20)
		22: 3.259815 -- 1.017931  (23)
		23: 3.048562 -- 1.537914  (8)
		24: 2.201004 -- 1.048392  (8)
		25: 3.179440 -- 1.606144  (5)
		26: 3.358282 -- 2.373815  (6)
		27: 2.748414 -- 1.026135  (10)
		28: 3.142127 -- 4.012307  (5)
	--> std: 1.663487 -- 0.820420

	2: 3.058322 (117)
		29: 3.553639 -- 1.492330  (8)
		30: 2.806782 -- 1.339737  (8)
		31: 2.184790 -- 0.914381  (7)
		32: 2.000654 -- 0.876962  (8)
		33: 0.719981 -- 0.417651  (4)
		34: 1.638182 -- 1.084975  (7)
		35: 1.370355 -- 0.796252  (4)
		36: 2.632471 -- 0.981932  (13)
		37: 3.733993 -- 1.852729  (8)
		38: 4.391881 -- 1.350333  (16)
		39: 4.088066 -- 2.590764  (15)
		40: 2.780297 -- 2.276463  (12)
		41: 3.823465 -- 3.401293  (7)
	--> std: 2.042737 -- 0.804672

	3: 2.287420 (251)
		42: 3.699595 -- 1.854348  (7)
		43: 1.837990 -- 0.691703  (9)
		44: 1.924016 -- 1.535767  (5)
		45: 1.745692 -- 0.782170  (6)
		46: 1.615930 -- 0.764673  (11)
		47: 1.748429 -- 1.391675  (5)
		48: 1.741912 -- 0.809833  (7)
		49: 1.969935 -- 1.005823  (9)
		50: 0.301245 -- 0.176034  (4)
		51: 0.638911 -- 0.373084  (4)
		52: 0.462491 -- 0.267280  (4)
		53: 0.611392 -- 0.358008  (4)
		54: 2.222492 -- 2.571863  (5)
		55: 1.336704 -- 0.787653  (4)
		56: 0.561410 -- 0.324511  (4)
		57: 2.060727 -- 0.853864  (16)
		58: 1.393208 -- 0.623772  (8)
		59: 1.862372 -- 0.940948  (11)
		60: 2.739723 -- 1.374137  (5)
		61: 2.877945 -- 1.381688  (24)
		62: 2.458760 -- 1.201747  (6)
		63: 1.937311 -- 0.678828  (13)
		64: 3.762668 -- 1.587124  (14)
		65: 3.157421 -- 2.110504  (8)
		66: 1.790925 -- 1.121673  (7)
		67: 0.899537 -- 0.526073  (4)
		68: 2.597334 -- 3.053664  (6)
		69: 2.202393 -- 1.275145  (4)
		70: 0.331041 -- 0.195356  (4)
		71: 1.716051 -- 2.643927  (5)
		72: 3.583204 -- 1.220872  (13)
		73: 3.376765 -- 1.530183  (8)
		74: 5.590361 -- 2.864343  (7)
	--> std: 1.746217 -- 0.763019

	Avg: 2.756491 -- 0.285363 
	Std: 1.791660 -- 0.147930 

Subclusters Formed: 75

Selecting Representatives:
Representatives:
[2, 2, 2, 2, 9, 3, 1, 2, 2, 3, 0, 1, 3, 4, 2, 3, 2, 1, 3, 4, 2, 1, 5, 2, 0, 2, 1, 0, 3, 0, 0, 0, 0, 3, 1, 1, 4, 0, 3, 0, 4, 2, 3, 2, 3, 0, 5, 1, 1, 1, 2, 3, 3, 0, 2, 1, 3, 0, 4, 2, 1, 4, 4, 5, 3, 1, 2, 2, 2, 3, 1, 1, 2, 2, 2]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 1
	{'neutral': [6]}
Number of Queries: 1

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[6]] 1

Connot Link Subcluster Constraints:
	[set([])] 1

Test All

Creating files for: _deploy
Creating Pairs
Train_data: (6, 1, 64, 64)
Data: (624, 1, 64, 64)
sims: (20,)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "data_p"
  top: "sims"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip1"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "data_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1_p"
  type: "Sigmoid"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sims"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (624, 1, 64, 64)
targets: (624,)
K: 1
Reclustering

~! 1 !~
Accuracy: 158 of 624: 25.321 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.248812



~! 2 !~
Accuracy: 158 of 624: 25.321 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.248812



~! 3 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001495 C: 0.001978 V: 0.001703 JCC: 0.172911



~! 4 !~
Accuracy: 161 of 624: 25.801 %
H: 0.000344 C: 0.000713 V: 0.000464 JCC: 0.202148



~! 5 !~
Accuracy: 172 of 624: 27.564 %
H: 0.002060 C: 0.004494 V: 0.002825 JCC: 0.207802



~! 6 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000654 C: 0.000742 V: 0.000695 JCC: 0.159998



~! 7 !~
Accuracy: 165 of 624: 26.442 %
H: 0.001099 C: 0.001433 V: 0.001244 JCC: 0.170607



~! 8 !~
Accuracy: 161 of 624: 25.801 %
H: 0.000290 C: 0.000368 V: 0.000324 JCC: 0.165176



~! 9 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001492 C: 0.001969 V: 0.001697 JCC: 0.172969



~! 10 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001205 C: 0.001669 V: 0.001400 JCC: 0.178785



~! 11 !~
Accuracy: 171 of 624: 27.404 %
H: 0.002437 C: 0.003076 V: 0.002720 JCC: 0.165305



~! 12 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000631 C: 0.000815 V: 0.000711 JCC: 0.168597



~! 13 !~
Accuracy: 165 of 624: 26.442 %
H: 0.001261 C: 0.001878 V: 0.001509 JCC: 0.190453



~! 14 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000377 C: 0.000487 V: 0.000425 JCC: 0.168411



~! 15 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001236 C: 0.001421 V: 0.001322 JCC: 0.164020



~! 16 !~
Accuracy: 173 of 624: 27.724 %
H: 0.002585 C: 0.002588 V: 0.002587 JCC: 0.141100



~! 17 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000613 C: 0.000655 V: 0.000633 JCC: 0.153126



~! 18 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000999 C: 0.001372 V: 0.001156 JCC: 0.176768



~! 19 !~
Accuracy: 171 of 624: 27.404 %
H: 0.003351 C: 0.003446 V: 0.003398 JCC: 0.147690



~! 20 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001443 C: 0.001570 V: 0.001504 JCC: 0.153785



~! 21 !~
Accuracy: 167 of 624: 26.763 %
H: 0.001310 C: 0.001355 V: 0.001332 JCC: 0.146831



~! 22 !~
Accuracy: 168 of 624: 26.923 %
H: 0.003650 C: 0.004180 V: 0.003897 JCC: 0.161941



~! 23 !~
Accuracy: 170 of 624: 27.244 %
H: 0.002281 C: 0.002362 V: 0.002321 JCC: 0.147419



~! 24 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001355 C: 0.001381 V: 0.001368 JCC: 0.144544



~! 25 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000876 C: 0.001123 V: 0.000984 JCC: 0.167211



~! 26 !~
Accuracy: 165 of 624: 26.442 %
H: 0.001276 C: 0.001464 V: 0.001364 JCC: 0.163677



~! 27 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001688 C: 0.001708 V: 0.001698 JCC: 0.143265



~! 28 !~
Accuracy: 171 of 624: 27.404 %
H: 0.002318 C: 0.002328 V: 0.002323 JCC: 0.141875



~! 29 !~
Accuracy: 172 of 624: 27.564 %
H: 0.001645 C: 0.001696 V: 0.001670 JCC: 0.146928



~! 30 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001206 C: 0.001227 V: 0.001216 JCC: 0.144003



~! 31 !~
Accuracy: 167 of 624: 26.763 %
H: 0.001439 C: 0.001468 V: 0.001454 JCC: 0.144845



~! 32 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001586 C: 0.001789 V: 0.001682 JCC: 0.160290



~! 33 !~
Accuracy: 170 of 624: 27.244 %
H: 0.001626 C: 0.001990 V: 0.001790 JCC: 0.173509



~! 34 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001407 C: 0.001472 V: 0.001439 JCC: 0.149969



~! 35 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001899 C: 0.002149 V: 0.002016 JCC: 0.163614



~! 36 !~
Accuracy: 162 of 624: 25.962 %
H: 0.000566 C: 0.000574 V: 0.000570 JCC: 0.143039



~! 37 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001106 C: 0.001191 V: 0.001147 JCC: 0.156652



~! 38 !~
Accuracy: 170 of 624: 27.244 %
H: 0.001735 C: 0.001936 V: 0.001830 JCC: 0.162527



~! 39 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001265 C: 0.001364 V: 0.001313 JCC: 0.157171



~! 40 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001801 C: 0.001847 V: 0.001824 JCC: 0.145898



~! 41 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000715 C: 0.000723 V: 0.000719 JCC: 0.142679



~! 42 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000954 C: 0.001001 V: 0.000977 JCC: 0.149876



~! 43 !~
Accuracy: 166 of 624: 26.603 %
H: 0.000918 C: 0.000996 V: 0.000956 JCC: 0.157263



~! 44 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001638 C: 0.001702 V: 0.001669 JCC: 0.149044



~! 45 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000438 C: 0.000459 V: 0.000448 JCC: 0.149603



~! 46 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000739 C: 0.000747 V: 0.000743 JCC: 0.142366



~! 47 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001540 C: 0.001636 V: 0.001587 JCC: 0.153394



~! 48 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000630 C: 0.000649 V: 0.000639 JCC: 0.147008



~! 49 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001723 C: 0.001836 V: 0.001778 JCC: 0.154668



~! 50 !~
Accuracy: 163 of 624: 26.122 %
H: 0.000496 C: 0.000509 V: 0.000502 JCC: 0.145442



~! 51 !~
Accuracy: 162 of 624: 25.962 %
H: 0.000298 C: 0.000302 V: 0.000300 JCC: 0.142703



~! 52 !~
Accuracy: 161 of 624: 25.801 %
H: 0.000265 C: 0.000271 V: 0.000268 JCC: 0.144903



~! 53 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000816 C: 0.000861 V: 0.000838 JCC: 0.151341



~! 54 !~
Accuracy: 166 of 624: 26.603 %
H: 0.000818 C: 0.000842 V: 0.000830 JCC: 0.146520



~! 55 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000645 C: 0.000694 V: 0.000669 JCC: 0.156272



~! 56 !~
Accuracy: 167 of 624: 26.763 %
H: 0.000975 C: 0.001003 V: 0.000989 JCC: 0.146294



~! 57 !~
Accuracy: 168 of 624: 26.923 %
H: 0.001082 C: 0.001159 V: 0.001119 JCC: 0.155115



~! 58 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001091 C: 0.001112 V: 0.001101 JCC: 0.144147



~! 59 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000692 C: 0.000720 V: 0.000706 JCC: 0.148898



~! 60 !~
Accuracy: 169 of 624: 27.083 %
H: 0.001245 C: 0.001291 V: 0.001268 JCC: 0.148485



~! 61 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000560 C: 0.000577 V: 0.000568 JCC: 0.146519



~! 62 !~
Accuracy: 167 of 624: 26.763 %
H: 0.000922 C: 0.000961 V: 0.000941 JCC: 0.149195



~! 63 !~
Accuracy: 166 of 624: 26.603 %
H: 0.000836 C: 0.000872 V: 0.000854 JCC: 0.148959



~! 64 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000701 C: 0.000727 V: 0.000714 JCC: 0.147649



~! 65 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000688 C: 0.000730 V: 0.000708 JCC: 0.153151



~! 66 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000593 C: 0.000608 V: 0.000601 JCC: 0.145458



~! 67 !~
Accuracy: 166 of 624: 26.603 %
H: 0.000967 C: 0.001011 V: 0.000989 JCC: 0.150288



~! 68 !~
Accuracy: 165 of 624: 26.442 %
H: 0.000734 C: 0.000756 V: 0.000745 JCC: 0.146976



~! 69 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000751 C: 0.000771 V: 0.000761 JCC: 0.145939



~! 70 !~
Accuracy: 166 of 624: 26.603 %
H: 0.001411 C: 0.001436 V: 0.001423 JCC: 0.144407



~! 71 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000750 C: 0.000766 V: 0.000758 JCC: 0.144944



~! 72 !~
Accuracy: 162 of 624: 25.962 %
H: 0.000293 C: 0.000299 V: 0.000296 JCC: 0.144748



~! 73 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000879 C: 0.000899 V: 0.000889 JCC: 0.144968



~! 74 !~
Accuracy: 164 of 624: 26.282 %
H: 0.000601 C: 0.000613 V: 0.000607 JCC: 0.144001


INCREMENT: (74)
SubClusters: 75
Accuracy: 199 of 624: 31.891 %
H: 0.032847 C: 0.010846 V: 0.016307 JCC: 0.011242


Final
Accuracy: 164 of 624: 26.282 %
H: 0.000601 C: 0.000613 V: 0.000607 JCC: 0.144001

Rows are labels, Columns are Clusters

      0   1   2   3
  0  48  40  39  28
  1  50  43  37  26
  2  52  45  35  26
  3  49  43  39  24



Total Time: 6 h 39 m 38.525586 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.1
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.1
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
