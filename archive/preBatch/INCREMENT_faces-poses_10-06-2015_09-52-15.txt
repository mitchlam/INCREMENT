./incDriver.py data/faces-poses.csv -k 20 -I -T -v 1


Using: data/faces-poses.csv (624)  --  (0.910985 s)
Initial Clustering: kmeans
Initial:  --  (1.803617 s)
Accuracy: 317 of 624: 50.801 %
H: 0.311382 C: 0.150260 V: 0.202703 JCC: 0.085614

Rows are labels, Columns are Clusters

      0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19
  0   8  11  12   6  26  12   0  18  16   0   8   8   0   8   7   0   8   0   8   0
  1   0   4  12  22  11   8  14   0   0   0   8   7  36   0   8  15   3   0   0   7
  2   8  12  12   0  32  12   0  18  16   0   8   8   0   7   8   0   8   0   7   0
  3  38   5  13   0   0  12   0  10   5  10  11   7   0   5   9   0   4  19   9   0




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 2.589797 (54)
		0: 1.906300 -- 0.686875  (13)
		1: 3.459786 -- 1.037386  (16)
		2: 1.281065 -- 0.543857  (8)
		3: 3.574671 -- 1.198991  (13)
		4: 0.747825 -- 0.462487  (4)
	--> std: 1.383294 -- 0.285263

	1: 2.225082 (32)
		5: 0.789169 -- 0.591999  (3)
		6: 1.118947 -- 0.666856  (4)
		7: 1.395805 -- 0.864311  (4)
		8: 2.798862 -- 0.768146  (21)
	--> std: 1.103312 -- 0.102860

	2: 2.733146 (49)
		9: 2.681279 -- 0.974172  (13)
		10: 0.813189 -- 0.488955  (4)
		11: 3.036693 -- 1.858000  (16)
		12: 2.181488 -- 1.259483  (4)
		13: 3.208477 -- 1.634398  (12)
	--> std: 1.610622 -- 0.484261

	3: 2.819618 (28)
		14: 2.917498 -- 1.032266  (14)
		15: 2.808057 -- 1.403541  (7)
		16: 2.635420 -- 1.935185  (7)
	--> std: 1.405279 -- 0.370548

	4: 1.765338 (69)
		17: 2.744381 -- 1.437809  (5)
		18: 1.341890 -- 0.537043  (8)
		19: 2.289087 -- 1.335871  (15)
		20: 2.241738 -- 1.917734  (9)
		21: 1.622638 -- 0.685534  (10)
		22: 0.638911 -- 0.373084  (4)
		23: 0.462491 -- 0.267280  (4)
		24: 0.647980 -- 0.378853  (4)
		25: 1.005527 -- 0.584205  (4)
		26: 2.598889 -- 3.118101  (6)
	--> std: 1.589153 -- 0.859914

	5: 2.259793 (44)
		27: 3.216671 -- 1.269028  (10)
		28: 1.584221 -- 0.782995  (11)
		29: 1.101362 -- 0.668021  (4)
		30: 1.898599 -- 1.127376  (4)
		31: 2.126089 -- 1.934895  (5)
		32: 2.720744 -- 1.798897  (10)
	--> std: 1.530574 -- 0.472839

	6: 2.794976 (14)
		33: 3.321193 -- 1.631943  (9)
		34: 1.847785 -- 1.016911  (5)
	--> std: 1.606186 -- 0.307516

	7: 2.417768 (46)
		35: 2.685595 -- 1.042151  (8)
		36: 1.791986 -- 0.680915  (9)
		37: 1.761157 -- 1.579481  (5)
		38: 2.855609 -- 1.526331  (10)
		39: 2.588772 -- 0.992663  (14)
	--> std: 1.242437 -- 0.341023

	8: 1.953311 (37)
		40: 1.533790 -- 1.284414  (5)
		41: 1.165129 -- 0.741307  (8)
		42: 0.989631 -- 0.592330  (4)
		43: 2.555171 -- 1.127705  (15)
		44: 2.599290 -- 3.567840  (5)
	--> std: 1.754192 -- 1.081996

	9: 3.087320 (10)
		45: 3.087320 -- 1.703795  (10)
	--> std: 1.703795 -- 0.000000

	10: 2.540606 (35)
		46: 2.804731 -- 1.080709  (11)
		47: 2.131992 -- 1.231112  (4)
		48: 3.965652 -- 3.005942  (7)
		49: 1.348351 -- 0.829428  (4)
		50: 0.898662 -- 0.533816  (4)
		51: 2.558719 -- 2.864020  (5)
	--> std: 2.132646 -- 0.975550

	11: 3.151283 (30)
		52: 3.312681 -- 1.054472  (23)
		53: 2.620975 -- 1.113740  (7)
	--> std: 1.107920 -- 0.029634

	12: 2.117274 (36)
		54: 2.914006 -- 1.554269  (8)
		55: 1.409344 -- 0.840053  (4)
		56: 0.634450 -- 0.405274  (4)
		57: 1.801348 -- 1.123782  (4)
		58: 1.748315 -- 0.763310  (7)
		59: 2.810117 -- 2.454376  (9)
	--> std: 1.729659 -- 0.665338

	13: 3.155187 (20)
		60: 3.065504 -- 1.619577  (5)
		61: 3.397604 -- 1.370752  (11)
		62: 2.600645 -- 1.505287  (4)
	--> std: 1.496061 -- 0.101694

	14: 3.448927 (32)
		63: 3.396009 -- 1.269985  (12)
		64: 3.480678 -- 1.766921  (20)
	--> std: 1.599299 -- 0.248468

	15: 2.397959 (15)
		65: 2.412888 -- 1.403609  (4)
		66: 1.488468 -- 0.859367  (4)
		67: 2.909136 -- 1.199255  (7)
	--> std: 1.317592 -- 0.224471

	16: 3.473961 (23)
		68: 3.473961 -- 0.980179  (23)
	--> std: 0.980179 -- 0.000000

	17: 3.040143 (19)
		69: 3.428025 -- 1.607134  (10)
		70: 2.609163 -- 1.909416  (9)
	--> std: 1.803765 -- 0.151141

	18: 1.359731 (24)
		71: 1.827060 -- 1.105059  (7)
		72: 0.946294 -- 0.546507  (4)
		73: 0.443800 -- 0.272355  (4)
		74: 0.826597 -- 0.477236  (4)
		75: 2.195472 -- 2.792053  (5)
	--> std: 1.582795 -- 0.919068

	19: 2.414614 (7)
		76: 2.414614 -- 1.020146  (7)
	--> std: 1.020146 -- 0.000000

	Avg: 2.587292 -- 0.542359 
	Std: 1.484945 -- 0.285461 

Subclusters Formed: 77

Selecting Representatives:
Representatives:
[5, 4, 1, 2, 1, 0, 3, 2, 3, 1, 3, 4, 3, 6, 7, 4, 1, 3, 3, 0, 1, 4, 3, 3, 0, 3, 1, 4, 1, 2, 2, 0, 0, 2, 2, 3, 0, 1, 3, 0, 2, 1, 1, 1, 2, 5, 7, 3, 0, 3, 2, 3, 7, 1, 4, 1, 1, 1, 0, 0, 2, 2, 3, 2, 6, 1, 3, 0, 0, 6, 0, 1, 3, 2, 0, 0, 5]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 1
	{'straight': [25]}
Number of Queries: 1

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[25]] 1

Connot Link Subcluster Constraints:
	[set([])] 1

Test All

Creating files for: _deploy
Creating Pairs
Train_data: (4, 1, 64, 64)
Data: (624, 1, 64, 64)
sims: (10,)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "data_p"
  top: "sims"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip1"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "data_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1_p"
  type: "Sigmoid"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sims"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (624, 1, 64, 64)
targets: (624,)
K: 1
Reclustering

~! 1 !~
Accuracy: 157 of 624: 25.160 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.248801



~! 2 !~
Accuracy: 203 of 624: 32.532 %
H: 0.017535 C: 0.035164 V: 0.023401 JCC: 0.209657



~! 3 !~
Accuracy: 274 of 624: 43.910 %
H: 0.130910 C: 0.266987 V: 0.175680 JCC: 0.282233



~! 4 !~
Accuracy: 217 of 624: 34.776 %
H: 0.069944 C: 0.077065 V: 0.073332 JCC: 0.170689



~! 5 !~
Accuracy: 226 of 624: 36.218 %
H: 0.089473 C: 0.099032 V: 0.094010 JCC: 0.176198



~! 6 !~
Accuracy: 189 of 624: 30.288 %
H: 0.010411 C: 0.015359 V: 0.012410 JCC: 0.191373



~! 7 !~
Accuracy: 240 of 624: 38.462 %
H: 0.069469 C: 0.091798 V: 0.079088 JCC: 0.211412



~! 8 !~
Accuracy: 222 of 624: 35.577 %
H: 0.037656 C: 0.043365 V: 0.040309 JCC: 0.182958



~! 9 !~
Accuracy: 347 of 624: 55.609 %
H: 0.298585 C: 0.314391 V: 0.306284 JCC: 0.286768



~! 10 !~
Accuracy: 216 of 624: 34.615 %
H: 0.037222 C: 0.042132 V: 0.039525 JCC: 0.179022



~! 11 !~
Accuracy: 340 of 624: 54.487 %
H: 0.234537 C: 0.269826 V: 0.250947 JCC: 0.287581



~! 12 !~
Accuracy: 276 of 624: 44.231 %
H: 0.115317 C: 0.130705 V: 0.122530 JCC: 0.223538



~! 13 !~
Accuracy: 268 of 624: 42.949 %
H: 0.120733 C: 0.140683 V: 0.129947 JCC: 0.211390



~! 14 !~
Accuracy: 280 of 624: 44.872 %
H: 0.188396 C: 0.195911 V: 0.192080 JCC: 0.229911



~! 15 !~
Accuracy: 232 of 624: 37.179 %
H: 0.043550 C: 0.048591 V: 0.045933 JCC: 0.179563



~! 16 !~
Accuracy: 245 of 624: 39.263 %
H: 0.062999 C: 0.069241 V: 0.065973 JCC: 0.189383



~! 17 !~
Accuracy: 268 of 624: 42.949 %
H: 0.085017 C: 0.095860 V: 0.090114 JCC: 0.208069



~! 18 !~
Accuracy: 282 of 624: 45.192 %
H: 0.121474 C: 0.131497 V: 0.126287 JCC: 0.219922



~! 19 !~
Accuracy: 268 of 624: 42.949 %
H: 0.097027 C: 0.102643 V: 0.099756 JCC: 0.203058



~! 20 !~
Accuracy: 270 of 624: 43.269 %
H: 0.072098 C: 0.073725 V: 0.072902 JCC: 0.180656



~! 21 !~
Accuracy: 307 of 624: 49.199 %
H: 0.141726 C: 0.144171 V: 0.142938 JCC: 0.220238



~! 22 !~
Accuracy: 287 of 624: 45.994 %
H: 0.113846 C: 0.118005 V: 0.115888 JCC: 0.206167



~! 23 !~
Accuracy: 308 of 624: 49.359 %
H: 0.172899 C: 0.186945 V: 0.179648 JCC: 0.250527



~! 24 !~
Accuracy: 276 of 624: 44.231 %
H: 0.112909 C: 0.117687 V: 0.115249 JCC: 0.197136



~! 25 !~
Accuracy: 331 of 624: 53.045 %
H: 0.188099 C: 0.195365 V: 0.191663 JCC: 0.255732



~! 26 !~
Accuracy: 330 of 624: 52.885 %
H: 0.217449 C: 0.218295 V: 0.217871 JCC: 0.251757



~! 27 !~
Accuracy: 336 of 624: 53.846 %
H: 0.214636 C: 0.228410 V: 0.221309 JCC: 0.266746



~! 28 !~
Accuracy: 316 of 624: 50.641 %
H: 0.152844 C: 0.154473 V: 0.153654 JCC: 0.223911



~! 29 !~
Accuracy: 318 of 624: 50.962 %
H: 0.157239 C: 0.159005 V: 0.158117 JCC: 0.229069



~! 30 !~
Accuracy: 315 of 624: 50.481 %
H: 0.152880 C: 0.164520 V: 0.158486 JCC: 0.232103



~! 31 !~
Accuracy: 288 of 624: 46.154 %
H: 0.127075 C: 0.131139 V: 0.129075 JCC: 0.208478



~! 32 !~
Accuracy: 335 of 624: 53.686 %
H: 0.199824 C: 0.204646 V: 0.202206 JCC: 0.250388



~! 33 !~
Accuracy: 328 of 624: 52.564 %
H: 0.192142 C: 0.198087 V: 0.195069 JCC: 0.249024



~! 34 !~
Accuracy: 345 of 624: 55.288 %
H: 0.226581 C: 0.229791 V: 0.228175 JCC: 0.259620



~! 35 !~
Accuracy: 357 of 624: 57.212 %
H: 0.237942 C: 0.238221 V: 0.238082 JCC: 0.274107



~! 36 !~
Accuracy: 321 of 624: 51.442 %
H: 0.170300 C: 0.177614 V: 0.173880 JCC: 0.239194



~! 37 !~
Accuracy: 362 of 624: 58.013 %
H: 0.266019 C: 0.273383 V: 0.269651 JCC: 0.279672



~! 38 !~
Accuracy: 337 of 624: 54.006 %
H: 0.192957 C: 0.200734 V: 0.196769 JCC: 0.249244



~! 39 !~
Accuracy: 328 of 624: 52.564 %
H: 0.231230 C: 0.241400 V: 0.236206 JCC: 0.246826



~! 40 !~
Accuracy: 361 of 624: 57.853 %
H: 0.249410 C: 0.250573 V: 0.249990 JCC: 0.277676



~! 41 !~
Accuracy: 357 of 624: 57.212 %
H: 0.252727 C: 0.256155 V: 0.254429 JCC: 0.272988



~! 42 !~
Accuracy: 357 of 624: 57.212 %
H: 0.239943 C: 0.241659 V: 0.240798 JCC: 0.271830



~! 43 !~
Accuracy: 346 of 624: 55.449 %
H: 0.218677 C: 0.220544 V: 0.219607 JCC: 0.260821



~! 44 !~
Accuracy: 372 of 624: 59.615 %
H: 0.293511 C: 0.298697 V: 0.296081 JCC: 0.301760



~! 45 !~
Accuracy: 354 of 624: 56.731 %
H: 0.248971 C: 0.256058 V: 0.252465 JCC: 0.274517



~! 46 !~
Accuracy: 370 of 624: 59.295 %
H: 0.280080 C: 0.280987 V: 0.280532 JCC: 0.294326



~! 47 !~
Accuracy: 367 of 624: 58.814 %
H: 0.260795 C: 0.264119 V: 0.262446 JCC: 0.286453



~! 48 !~
Accuracy: 370 of 624: 59.295 %
H: 0.272763 C: 0.274039 V: 0.273399 JCC: 0.290986



~! 49 !~
Accuracy: 367 of 624: 58.814 %
H: 0.276337 C: 0.278852 V: 0.277589 JCC: 0.299135



~! 50 !~
Accuracy: 396 of 624: 63.462 %
H: 0.331529 C: 0.332927 V: 0.332226 JCC: 0.334792



~! 51 !~
Accuracy: 398 of 624: 63.782 %
H: 0.339969 C: 0.340204 V: 0.340087 JCC: 0.337847



~! 52 !~
Accuracy: 385 of 624: 61.699 %
H: 0.317848 C: 0.319220 V: 0.318533 JCC: 0.311140



~! 53 !~
Accuracy: 399 of 624: 63.942 %
H: 0.342837 C: 0.347960 V: 0.345379 JCC: 0.339182



~! 54 !~
Accuracy: 412 of 624: 66.026 %
H: 0.357139 C: 0.361933 V: 0.359520 JCC: 0.350561



~! 55 !~
Accuracy: 401 of 624: 64.263 %
H: 0.361885 C: 0.363787 V: 0.362833 JCC: 0.339667



~! 56 !~
Accuracy: 410 of 624: 65.705 %
H: 0.370978 C: 0.372556 V: 0.371765 JCC: 0.353417



~! 57 !~
Accuracy: 419 of 624: 67.147 %
H: 0.386947 C: 0.388552 V: 0.387748 JCC: 0.363858



~! 58 !~
Accuracy: 410 of 624: 65.705 %
H: 0.370217 C: 0.370665 V: 0.370441 JCC: 0.349105



~! 59 !~
Accuracy: 411 of 624: 65.865 %
H: 0.369437 C: 0.369892 V: 0.369664 JCC: 0.348626



~! 60 !~
Accuracy: 424 of 624: 67.949 %
H: 0.382041 C: 0.383335 V: 0.382687 JCC: 0.364406



~! 61 !~
Accuracy: 422 of 624: 67.628 %
H: 0.397758 C: 0.399814 V: 0.398783 JCC: 0.363054



~! 62 !~
Accuracy: 411 of 624: 65.865 %
H: 0.386553 C: 0.392268 V: 0.389390 JCC: 0.355122



~! 63 !~
Accuracy: 419 of 624: 67.147 %
H: 0.404713 C: 0.406542 V: 0.405625 JCC: 0.370949



~! 64 !~
Accuracy: 428 of 624: 68.590 %
H: 0.440232 C: 0.442601 V: 0.441413 JCC: 0.386455



~! 65 !~
Accuracy: 425 of 624: 68.109 %
H: 0.414100 C: 0.415628 V: 0.414863 JCC: 0.378583



~! 66 !~
Accuracy: 425 of 624: 68.109 %
H: 0.442929 C: 0.445966 V: 0.444443 JCC: 0.385312



~! 67 !~
Accuracy: 437 of 624: 70.032 %
H: 0.432927 C: 0.435486 V: 0.434203 JCC: 0.391376



~! 68 !~
Accuracy: 435 of 624: 69.712 %
H: 0.455378 C: 0.459160 V: 0.457261 JCC: 0.392488



~! 69 !~
Accuracy: 448 of 624: 71.795 %
H: 0.468317 C: 0.473105 V: 0.470698 JCC: 0.407167



~! 70 !~
Accuracy: 455 of 624: 72.917 %
H: 0.463761 C: 0.470547 V: 0.467129 JCC: 0.415771



~! 71 !~
Accuracy: 449 of 624: 71.955 %
H: 0.466843 C: 0.471036 V: 0.468930 JCC: 0.406727



~! 72 !~
Accuracy: 453 of 624: 72.596 %
H: 0.467005 C: 0.472044 V: 0.469511 JCC: 0.409037



~! 73 !~
Accuracy: 455 of 624: 72.917 %
H: 0.475097 C: 0.480186 V: 0.477628 JCC: 0.414437



~! 74 !~
Accuracy: 453 of 624: 72.596 %
H: 0.472325 C: 0.476860 V: 0.474582 JCC: 0.411930



~! 75 !~
Accuracy: 462 of 624: 74.038 %
H: 0.482867 C: 0.488314 V: 0.485575 JCC: 0.425872



~! 76 !~
Accuracy: 466 of 624: 74.679 %
H: 0.488795 C: 0.495006 V: 0.491881 JCC: 0.432224


INCREMENT: (76)
SubClusters: 77
Accuracy: 464 of 624: 74.359 %
H: 0.655283 C: 0.216628 V: 0.325613 JCC: 0.033949


Final
Accuracy: 466 of 624: 74.679 %
H: 0.488795 C: 0.495006 V: 0.491881 JCC: 0.432224

Rows are labels, Columns are Clusters

       0    1    2   3
  0   53    3   10  90
  1   15    0  133   7
  2  124    1    0  31
  3   12  119    6  20



Total Time: 6 h 49 m 19.459289 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.1
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.1
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
