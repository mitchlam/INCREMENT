./incDriver.py data/washpass_final.csv -i pre -T -v 1


Using: data/washpass_final.csv (2000)  --  (0.163137 s)
Initial Clustering: pre
Initial:  --  (0.048365 s)
Accuracy: 1959 of 2000: 97.950 %
H: 0.920071 C: 0.535716 V: 0.677155 JCC: 0.669367

Rows are labels, Columns are Clusters

       0    1    2    3
  0  776    1   40  183
  1    0  826  174    0




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 3.129717 (776)
		0: 2.635294 -- 0.639301  (21)
		1: 2.336475 -- 0.553129  (20)
		2: 2.563536 -- 0.454799  (43)
		3: 2.865629 -- 0.586752  (38)
		4: 1.674261 -- 0.411541  (33)
		5: 1.583757 -- 0.562201  (9)
		6: 2.330769 -- 0.728634  (40)
		7: 1.500020 -- 0.508598  (10)
		8: 2.097405 -- 0.565737  (38)
		9: 2.464597 -- 0.852748  (12)
		10: 2.976312 -- 0.822885  (16)
		11: 3.102042 -- 1.035494  (12)
		12: 2.954829 -- 0.882888  (16)
		13: 3.199312 -- 0.886641  (23)
		14: 2.666008 -- 1.100347  (7)
		15: 2.681424 -- 1.019391  (8)
		16: 3.019893 -- 0.722209  (20)
		17: 3.494408 -- 0.763605  (29)
		18: 3.125442 -- 0.483997  (59)
		19: 2.786396 -- 1.137957  (7)
		20: 3.080172 -- 0.998490  (11)
		21: 3.044038 -- 0.605858  (29)
		22: 3.481548 -- 0.689297  (33)
		23: 3.445191 -- 1.347718  (8)
		24: 3.673504 -- 0.592737  (41)
		25: 4.091468 -- 0.833592  (26)
		26: 3.878417 -- 0.719243  (48)
		27: 3.927700 -- 0.692509  (35)
		28: 4.447735 -- 0.834804  (31)
		29: 4.306813 -- 1.202674  (17)
		30: 4.360958 -- 1.254377  (17)
		31: 4.621089 -- 2.199198  (6)
		32: 3.846189 -- 2.382569  (9)
		33: 4.044647 -- 2.335186  (4)
	--> std: 1.111869 -- 0.489793

	1: 2.656584 (827)
		34: 2.088503 -- 0.611964  (22)
		35: 2.401331 -- 0.433359  (49)
		36: 2.580260 -- 0.543405  (34)
		37: 2.980742 -- 0.606956  (48)
		38: 1.595408 -- 0.558631  (11)
		39: 1.541229 -- 0.426698  (22)
		40: 1.459282 -- 0.378709  (18)
		41: 2.049531 -- 0.489487  (30)
		42: 2.005816 -- 0.641918  (16)
		43: 2.221798 -- 0.922304  (7)
		44: 1.659150 -- 0.508673  (12)
		45: 2.103183 -- 0.533180  (18)
		46: 2.289837 -- 0.623727  (16)
		47: 2.790788 -- 0.523513  (45)
		48: 1.786679 -- 0.391164  (28)
		49: 2.884651 -- 0.626900  (91)
		50: 2.956814 -- 0.879940  (13)
		51: 3.461297 -- 0.786559  (33)
		52: 3.797205 -- 0.908736  (22)
		53: 3.696162 -- 1.056978  (30)
		54: 4.039082 -- 1.026401  (23)
		55: 2.251113 -- 0.754748  (40)
		56: 1.817265 -- 0.321172  (55)
		57: 2.237996 -- 0.461138  (35)
		58: 2.724904 -- 0.562727  (34)
		59: 2.886417 -- 0.782637  (38)
		60: 4.663919 -- 1.351202  (37)
	--> std: 1.021223 -- 0.237867

	2: 3.801340 (214)
		61: 4.021938 -- 2.843955  (3)
		62: 2.681003 -- 0.909570  (10)
		63: 2.062745 -- 0.879067  (11)
		64: 3.887577 -- 1.269140  (62)
		65: 2.713320 -- 1.646943  (39)
		66: 4.289121 -- 1.182940  (22)
		67: 4.009664 -- 1.143988  (15)
		68: 4.818575 -- 1.398160  (52)
	--> std: 1.604643 -- 0.590231

	3: 2.867013 (183)
		69: 2.504826 -- 0.725190  (18)
		70: 2.434499 -- 0.547469  (28)
		71: 1.699656 -- 0.483724  (14)
		72: 2.528823 -- 0.570508  (63)
		73: 3.721135 -- 0.754163  (55)
		74: 4.727412 -- 2.441194  (5)
	--> std: 1.029697 -- 0.686870

	Avg: 3.113664 -- 0.430963 
	Std: 1.191858 -- 0.240937 

Subclusters Formed: 75

Selecting Representatives:
Representatives:
[5, 0, 0, 8, 12, 5, 3, 3, 3, 1, 0, 0, 0, 0, 0, 3, 6, 1, 1, 2, 1, 4, 0, 0, 29, 0, 9, 14, 6, 0, 3, 2, 2, 3, 2, 1, 3, 0, 9, 1, 0, 3, 3, 0, 0, 0, 0, 0, 2, 9, 0, 5, 2, 1, 1, 3, 5, 0, 0, 2, 1, 1, 6, 5, 0, 2, 13, 0, 0, 0, 6, 10, 2, 4, 3]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 1
	{'AirlineList': [40]}
Number of Queries: 1

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[40]] 1

Connot Link Subcluster Constraints:
	[set([])] 1

Test All

Creating files for: _deploy
Creating Pairs
Train_data: (18, 268)
Data: (2000, 268)
sims: (160,)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "data_p"
  top: "sims"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "s2"
  type: "Sigmoid"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "data_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1_p"
  type: "Sigmoid"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "s2_p"
  type: "Sigmoid"
  bottom: "ip2_p"
  top: "ip2_p"
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sims"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (2000, 268)
targets: (2000,)
K: 1
Reclustering

~! 1 !~
Accuracy: 1000 of 2000: 50.000 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.499750



~! 2 !~
Accuracy: 1000 of 2000: 50.000 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.499750



~! 3 !~
Accuracy: 1987 of 2000: 99.350 %
H: 0.949837 C: 0.949953 V: 0.949895 JCC: 0.974475



~! 4 !~
Accuracy: 1992 of 2000: 99.600 %
H: 0.966343 C: 0.966388 V: 0.966365 JCC: 0.984175



~! 5 !~
Accuracy: 1982 of 2000: 99.100 %
H: 0.927205 C: 0.927248 V: 0.927227 JCC: 0.964916



~! 6 !~
Accuracy: 1988 of 2000: 99.400 %
H: 0.947204 C: 0.947206 V: 0.947205 JCC: 0.976402



~! 7 !~
Accuracy: 1976 of 2000: 98.800 %
H: 0.913041 C: 0.913304 V: 0.913172 JCC: 0.953638



~! 8 !~
Accuracy: 1988 of 2000: 99.400 %
H: 0.949150 C: 0.949194 V: 0.949172 JCC: 0.976403



~! 9 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 10 !~
Accuracy: 1994 of 2000: 99.700 %
H: 0.971577 C: 0.971588 V: 0.971583 JCC: 0.988095



~! 11 !~
Accuracy: 1994 of 2000: 99.700 %
H: 0.971577 C: 0.971588 V: 0.971583 JCC: 0.988095



~! 12 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 13 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 14 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 15 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 16 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 17 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 18 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 19 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 20 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 21 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 22 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 23 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 24 !~
Accuracy: 1994 of 2000: 99.700 %
H: 0.970536 C: 0.970536 V: 0.970536 JCC: 0.988095



~! 25 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 26 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 27 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 28 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 29 !~
Accuracy: 1993 of 2000: 99.650 %
H: 0.966456 C: 0.966457 V: 0.966456 JCC: 0.986132



~! 30 !~
Accuracy: 1994 of 2000: 99.700 %
H: 0.970536 C: 0.970536 V: 0.970536 JCC: 0.988095



~! 31 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 32 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 33 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 34 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 35 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 36 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 37 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 38 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 39 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 40 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 41 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 42 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 43 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 44 !~
Accuracy: 1995 of 2000: 99.750 %
H: 0.975478 C: 0.975485 V: 0.975482 JCC: 0.990065



~! 45 !~
Accuracy: 1996 of 2000: 99.800 %
H: 0.979561 C: 0.979564 V: 0.979563 JCC: 0.992040



~! 46 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 47 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 48 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.985261 C: 0.985268 V: 0.985265 JCC: 0.994021



~! 49 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 50 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 51 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 52 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 53 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 54 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 55 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 56 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.989590 C: 0.989593 V: 0.989592 JCC: 0.996008



~! 57 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 58 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 59 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 60 !~
Accuracy: 1997 of 2000: 99.850 %
H: 0.983888 C: 0.983889 V: 0.983889 JCC: 0.994021



~! 61 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 62 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 63 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 64 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001



~! 65 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001



~! 66 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 67 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 68 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001



~! 69 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001



~! 70 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001



~! 71 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 72 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 73 !~
Accuracy: 1998 of 2000: 99.900 %
H: 0.988592 C: 0.988592 V: 0.988592 JCC: 0.996008



~! 74 !~
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001


INCREMENT: (74)
SubClusters: 75
Accuracy: 1992 of 2000: 99.600 %
H: 0.976825 C: 0.164242 V: 0.281203 JCC: 0.036125


Final
Accuracy: 1999 of 2000: 99.950 %
H: 0.994295 C: 0.994296 V: 0.994296 JCC: 0.998001

Rows are labels, Columns are Clusters

       0     1
  0    0  1000
  1  999     1



Total Time: 49 m 18.347898 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.1
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.1
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
