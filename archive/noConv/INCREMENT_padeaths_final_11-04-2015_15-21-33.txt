./incDriver.py data/padeaths_final.csv -i pre -S 2 -T -v 1


Using: data/padeaths_final.csv (4974)  --  (0.638876 s)
Initial Clustering: pre
Initial:  --  (0.166270 s)
Accuracy: 4110 of 4974: 82.630 %
H: 0.580722 C: 0.409397 V: 0.480237 JCC: 0.367172

Rows are labels, Columns are Clusters

        0     1    2    3    4    5
  0    43     0    2   46    0    0
  1   116     1  365   92    4    0
  2     1  1128    2   17  577  152
  3    62     0    4   94    5    0
  4  1168     0  697  388    5    5




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 6.990590 (1390)
		0: 6.278638 -- 1.340787  (24)
		1: 5.306838 -- 0.810968  (50)
		2: 6.367942 -- 1.583829  (19)
		3: 4.957726 -- 0.983988  (30)
		4: 6.174781 -- 0.934232  (56)
		5: 6.589325 -- 1.385220  (30)
		6: 5.920539 -- 2.125961  (9)
		7: 6.567970 -- 0.999936  (54)
		8: 6.612629 -- 1.042428  (44)
		9: 6.885159 -- 0.959690  (57)
		10: 7.434082 -- 1.452983  (28)
		11: 6.033438 -- 1.642548  (41)
		12: 5.646188 -- 1.418920  (17)
		13: 6.182988 -- 1.105277  (41)
		14: 7.382101 -- 1.216451  (51)
		15: 5.762526 -- 1.545209  (15)
		16: 6.154888 -- 1.106083  (36)
		17: 6.720705 -- 1.638890  (19)
		18: 6.439660 -- 1.002033  (51)
		19: 7.658732 -- 1.678430  (23)
		20: 7.128369 -- 1.657861  (26)
		21: 6.664756 -- 1.134256  (37)
		22: 7.020701 -- 1.113073  (44)
		23: 6.472895 -- 2.683516  (7)
		24: 7.033189 -- 1.395574  (27)
		25: 6.918580 -- 1.281531  (34)
		26: 7.326935 -- 1.197476  (44)
		27: 6.579981 -- 2.710793  (7)
		28: 6.656050 -- 1.410742  (24)
		29: 7.579976 -- 0.642960  (165)
		30: 8.171607 -- 1.584173  (29)
		31: 7.345847 -- 1.238597  (40)
		32: 7.650790 -- 1.135376  (49)
		33: 8.385742 -- 0.935721  (86)
		34: 8.217090 -- 1.715610  (27)
		35: 8.890865 -- 1.506463  (49)
	--> std: 1.497904 -- 0.441070

	1: 5.113596 (1129)
		36: 3.184644 -- 1.300173  (8)
		37: 3.690748 -- 0.661144  (39)
		38: 3.234517 -- 0.623686  (34)
		39: 2.851504 -- 1.014049  (9)
		40: 3.130806 -- 1.016458  (12)
		41: 2.549492 -- 1.476561  (4)
		42: 3.953317 -- 0.618088  (53)
		43: 4.468287 -- 1.191471  (17)
		44: 4.513166 -- 0.952016  (32)
		45: 4.500833 -- 0.941355  (35)
		46: 3.645371 -- 0.837356  (21)
		47: 4.069422 -- 0.947979  (23)
		48: 4.051761 -- 1.378959  (10)
		49: 4.641953 -- 0.561688  (84)
		50: 5.181541 -- 0.782182  (49)
		51: 4.527345 -- 1.045593  (20)
		52: 4.983198 -- 0.655431  (71)
		53: 5.000610 -- 0.640869  (70)
		54: 5.563711 -- 0.820610  (57)
		55: 5.022370 -- 1.015509  (37)
		56: 4.710054 -- 1.446011  (12)
		57: 5.598382 -- 0.738205  (63)
		58: 6.190104 -- 1.475429  (19)
		59: 5.872580 -- 1.325847  (21)
		60: 5.729006 -- 1.775051  (15)
		61: 5.562421 -- 0.983172  (38)
		62: 5.284247 -- 1.770510  (10)
		63: 5.186500 -- 2.117459  (7)
		64: 6.374901 -- 0.848037  (75)
		65: 5.115681 -- 1.071972  (63)
		66: 6.938167 -- 1.150656  (42)
		67: 7.244123 -- 2.238874  (23)
		68: 6.864692 -- 1.767639  (49)
		69: 7.106599 -- 3.101041  (7)
	--> std: 1.466513 -- 0.540298

	2: 6.897547 (1070)
		70: 6.056565 -- 1.528705  (20)
		71: 5.508192 -- 1.481861  (15)
		72: 5.242935 -- 1.336856  (17)
		73: 5.954196 -- 1.276576  (24)
		74: 5.257665 -- 2.366456  (6)
		75: 6.302508 -- 1.468792  (21)
		76: 5.833939 -- 1.139673  (34)
		77: 5.046600 -- 1.562900  (12)
		78: 5.303899 -- 0.842613  (68)
		79: 5.432975 -- 1.326260  (18)
		80: 5.552882 -- 1.432948  (18)
		81: 6.123476 -- 1.516418  (19)
		82: 6.614909 -- 1.416824  (25)
		83: 6.749584 -- 2.071571  (12)
		84: 7.672681 -- 4.430076  (4)
		85: 5.480304 -- 2.238524  (7)
		86: 6.182603 -- 1.404819  (21)
		87: 6.992106 -- 2.011000  (15)
		88: 6.764341 -- 1.513035  (29)
		89: 5.551159 -- 2.105238  (8)
		90: 6.638808 -- 0.969784  (54)
		91: 7.320716 -- 1.810451  (19)
		92: 7.190943 -- 0.911249  (81)
		93: 6.947950 -- 1.058338  (79)
		94: 7.065424 -- 0.885006  (70)
		95: 6.481185 -- 1.810986  (14)
		96: 7.100522 -- 1.779340  (18)
		97: 7.122693 -- 1.420374  (29)
		98: 7.785088 -- 2.308228  (13)
		99: 7.682720 -- 1.139088  (49)
		100: 8.025959 -- 0.809313  (110)
		101: 7.404657 -- 3.124042  (7)
		102: 6.311900 -- 1.440775  (29)
		103: 8.688472 -- 1.083151  (105)
	--> std: 1.642550 -- 0.698940

	3: 7.586960 (637)
		104: 7.486997 -- 8.568831  (633)
		105: 23.406077 -- 13.522767  (4)
	--> std: 8.700196 -- 2.476968

	4: 6.486207 (591)
		106: 3.816001 -- 0.649918  (47)
		107: 5.095997 -- 0.873323  (56)
		108: 6.124382 -- 1.385093  (37)
		109: 6.886143 -- 1.837393  (23)
		110: 6.112597 -- 1.132949  (31)
		111: 6.469685 -- 1.137042  (43)
		112: 5.900191 -- 1.546937  (16)
		113: 6.156641 -- 0.908561  (50)
		114: 6.871798 -- 1.426512  (27)
		115: 7.103472 -- 1.518666  (26)
		116: 6.010169 -- 3.019649  (5)
		117: 7.208786 -- 0.866752  (110)
		118: 7.334330 -- 2.264250  (15)
		119: 6.316892 -- 1.422192  (22)
		120: 7.779847 -- 1.323524  (41)
		121: 8.510600 -- 1.803075  (27)
		122: 8.181498 -- 2.255214  (15)
	--> std: 1.725679 -- 0.587089

	5: 6.929336 (157)
		123: 7.203831 -- 3.603129  (5)
		124: 5.385010 -- 2.059791  (8)
		125: 4.799666 -- 2.157709  (6)
		126: 6.161561 -- 1.523064  (21)
		127: 7.270220 -- 1.120937  (117)
	--> std: 1.586482 -- 0.843269

	Avg: 6.667373 -- 0.765806 
	Std: 2.769887 -- 2.653519 

Subclusters Formed: 128

Selecting Representatives:
Representatives:
[9, 3, 0, 1, 0, 0, 0, 14, 2, 12, 1, 2, 2, 2, 7, 1, 4, 4, 6, 11, 0, 7, 8, 0, 0, 0, 16, 2, 5, 101, 0, 10, 0, 20, 0, 7, 1, 0, 2, 2, 0, 0, 0, 0, 4, 7, 11, 0, 1, 2, 8, 6, 34, 0, 12, 2, 0, 14, 10, 2, 0, 0, 0, 3, 4, 2, 10, 6, 12, 3, 6, 1, 2, 0, 0, 0, 6, 0, 6, 0, 0, 0, 8, 1, 0, 0, 3, 0, 2, 0, 5, 0, 1, 18, 0, 2, 3, 1, 5, 5, 1, 3, 0, 25, 218, 2, 4, 19, 0, 0, 5, 0, 0, 6, 0, 3, 0, 7, 3, 3, 6, 3, 0, 0, 1, 0, 11, 32]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 2
	{'Type2': [12]}
	{'Type4': [105]}
Number of Queries: 2

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[105], [12]] 2

Connot Link Subcluster Constraints:
	[set([1]), set([0])] 2

Test All

Creating files for: _deploy
Train_data: (21, 403)
Data: (4974, 403)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 250
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "s2"
  type: "Sigmoid"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "WrapperContrastiveLoss"
  bottom: "feat"
  bottom: "labels"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (4974, 403)
targets: (4974,)
K: 2
Reclustering

~! 2 !~
Accuracy: 3766 of 4974: 75.714 %
H: 0.301219 C: 0.523195 V: 0.382323 JCC: 0.520591



~! 4 !~
Accuracy: 3842 of 4974: 77.242 %
H: 0.431122 C: 0.456163 V: 0.443289 JCC: 0.465704



~! 6 !~
Accuracy: 4053 of 4974: 81.484 %
H: 0.497357 C: 0.529543 V: 0.512946 JCC: 0.543982



~! 8 !~
Accuracy: 4094 of 4974: 82.308 %
H: 0.543195 C: 0.585026 V: 0.563335 JCC: 0.591890



~! 10 !~
Accuracy: 4028 of 4974: 80.981 %
H: 0.502131 C: 0.548270 V: 0.524187 JCC: 0.582427



~! 12 !~
Accuracy: 4027 of 4974: 80.961 %
H: 0.500912 C: 0.561860 V: 0.529638 JCC: 0.586850



~! 14 !~
Accuracy: 4076 of 4974: 81.946 %
H: 0.552806 C: 0.602812 V: 0.576727 JCC: 0.612303



~! 16 !~
Accuracy: 4096 of 4974: 82.348 %
H: 0.558897 C: 0.601556 V: 0.579442 JCC: 0.607039



~! 18 !~
Accuracy: 4074 of 4974: 81.906 %
H: 0.530138 C: 0.570101 V: 0.549394 JCC: 0.581834



~! 20 !~
Accuracy: 4076 of 4974: 81.946 %
H: 0.535002 C: 0.571335 V: 0.552572 JCC: 0.570715



~! 22 !~
Accuracy: 4068 of 4974: 81.785 %
H: 0.515648 C: 0.565456 V: 0.539405 JCC: 0.573722



~! 24 !~
Accuracy: 4072 of 4974: 81.866 %
H: 0.528967 C: 0.575240 V: 0.551134 JCC: 0.581864



~! 26 !~
Accuracy: 4019 of 4974: 80.800 %
H: 0.569263 C: 0.525473 V: 0.546493 JCC: 0.564997



~! 28 !~
Accuracy: 4096 of 4974: 82.348 %
H: 0.611965 C: 0.571529 V: 0.591056 JCC: 0.632666



~! 30 !~
Accuracy: 4065 of 4974: 81.725 %
H: 0.618049 C: 0.559425 V: 0.587277 JCC: 0.608589



~! 32 !~
Accuracy: 4035 of 4974: 81.122 %
H: 0.604304 C: 0.551134 V: 0.576495 JCC: 0.594697



~! 34 !~
Accuracy: 4080 of 4974: 82.027 %
H: 0.586856 C: 0.538255 V: 0.561506 JCC: 0.585822



~! 36 !~
Accuracy: 4174 of 4974: 83.916 %
H: 0.629012 C: 0.579293 V: 0.603129 JCC: 0.634028



~! 38 !~
Accuracy: 4099 of 4974: 82.409 %
H: 0.601481 C: 0.555791 V: 0.577734 JCC: 0.609761



~! 40 !~
Accuracy: 4132 of 4974: 83.072 %
H: 0.624050 C: 0.580236 V: 0.601346 JCC: 0.643583



~! 42 !~
Accuracy: 4102 of 4974: 82.469 %
H: 0.594367 C: 0.526406 V: 0.558326 JCC: 0.562292



~! 44 !~
Accuracy: 4324 of 4974: 86.932 %
H: 0.657197 C: 0.626020 V: 0.641230 JCC: 0.696895



~! 46 !~
Accuracy: 4170 of 4974: 83.836 %
H: 0.630548 C: 0.589423 V: 0.609292 JCC: 0.653501



~! 48 !~
Accuracy: 4196 of 4974: 84.359 %
H: 0.629951 C: 0.596428 V: 0.612731 JCC: 0.664818



~! 50 !~
Accuracy: 4270 of 4974: 85.846 %
H: 0.642464 C: 0.606026 V: 0.623713 JCC: 0.668780



~! 52 !~
Accuracy: 4237 of 4974: 85.183 %
H: 0.647631 C: 0.618588 V: 0.632776 JCC: 0.686818



~! 54 !~
Accuracy: 4307 of 4974: 86.590 %
H: 0.665393 C: 0.641071 V: 0.653006 JCC: 0.709641



~! 56 !~
Accuracy: 4221 of 4974: 84.861 %
H: 0.638818 C: 0.584878 V: 0.610659 JCC: 0.633173



~! 58 !~
Accuracy: 4226 of 4974: 84.962 %
H: 0.636896 C: 0.581308 V: 0.607834 JCC: 0.630044



~! 60 !~
Accuracy: 4274 of 4974: 85.927 %
H: 0.651224 C: 0.628816 V: 0.639823 JCC: 0.694247



~! 62 !~
Accuracy: 4241 of 4974: 85.263 %
H: 0.649241 C: 0.619204 V: 0.633867 JCC: 0.677800



~! 64 !~
Accuracy: 4250 of 4974: 85.444 %
H: 0.653305 C: 0.629211 V: 0.641032 JCC: 0.693541



~! 66 !~
Accuracy: 4409 of 4974: 88.641 %
H: 0.694016 C: 0.559790 V: 0.619718 JCC: 0.592463



~! 68 !~
Accuracy: 4253 of 4974: 85.505 %
H: 0.651915 C: 0.511627 V: 0.573314 JCC: 0.559714



~! 70 !~
Accuracy: 4272 of 4974: 85.887 %
H: 0.646105 C: 0.508997 V: 0.569414 JCC: 0.563356



~! 72 !~
Accuracy: 4301 of 4974: 86.470 %
H: 0.655246 C: 0.519488 V: 0.579523 JCC: 0.573422



~! 74 !~
Accuracy: 4198 of 4974: 84.399 %
H: 0.629228 C: 0.493494 V: 0.553156 JCC: 0.552005



~! 76 !~
Accuracy: 4211 of 4974: 84.660 %
H: 0.633008 C: 0.499678 V: 0.558496 JCC: 0.558913



~! 78 !~
Accuracy: 4264 of 4974: 85.726 %
H: 0.644504 C: 0.514202 V: 0.572027 JCC: 0.580655



~! 80 !~
Accuracy: 4236 of 4974: 85.163 %
H: 0.638842 C: 0.503471 V: 0.563135 JCC: 0.563631



~! 82 !~
Accuracy: 4318 of 4974: 86.811 %
H: 0.665698 C: 0.528808 V: 0.589409 JCC: 0.584464



~! 84 !~
Accuracy: 4234 of 4974: 85.123 %
H: 0.640534 C: 0.506532 V: 0.565706 JCC: 0.569815



~! 86 !~
Accuracy: 4310 of 4974: 86.651 %
H: 0.654626 C: 0.519621 V: 0.579362 JCC: 0.577667



~! 88 !~
Accuracy: 4237 of 4974: 85.183 %
H: 0.632755 C: 0.503120 V: 0.560540 JCC: 0.570868



~! 90 !~
Accuracy: 4307 of 4974: 86.590 %
H: 0.655459 C: 0.523699 V: 0.582217 JCC: 0.588847



~! 92 !~
Accuracy: 4327 of 4974: 86.992 %
H: 0.662622 C: 0.530008 V: 0.588942 JCC: 0.591199



~! 94 !~
Accuracy: 4293 of 4974: 86.309 %
H: 0.651227 C: 0.518606 V: 0.577399 JCC: 0.581182



~! 96 !~
Accuracy: 4403 of 4974: 88.520 %
H: 0.684178 C: 0.551578 V: 0.610764 JCC: 0.607019



~! 98 !~
Accuracy: 4399 of 4974: 88.440 %
H: 0.688023 C: 0.550152 V: 0.611411 JCC: 0.604615



~! 100 !~
Accuracy: 4434 of 4974: 89.144 %
H: 0.698776 C: 0.557118 V: 0.619958 JCC: 0.600301



~! 102 !~
Accuracy: 4390 of 4974: 88.259 %
H: 0.678306 C: 0.542329 V: 0.602744 JCC: 0.597384



~! 104 !~
Accuracy: 4416 of 4974: 88.782 %
H: 0.692413 C: 0.552536 V: 0.614617 JCC: 0.601567



~! 106 !~
Accuracy: 4430 of 4974: 89.063 %
H: 0.693864 C: 0.556621 V: 0.617711 JCC: 0.604118



~! 108 !~
Accuracy: 4404 of 4974: 88.540 %
H: 0.682692 C: 0.544692 V: 0.605934 JCC: 0.594687



~! 110 !~
Accuracy: 4424 of 4974: 88.943 %
H: 0.691048 C: 0.554136 V: 0.615065 JCC: 0.605151



~! 112 !~
Accuracy: 4420 of 4974: 88.862 %
H: 0.690053 C: 0.556327 V: 0.616016 JCC: 0.611613



~! 114 !~
Accuracy: 4436 of 4974: 89.184 %
H: 0.694754 C: 0.556286 V: 0.617857 JCC: 0.602737



~! 116 !~
Accuracy: 4408 of 4974: 88.621 %
H: 0.684050 C: 0.545166 V: 0.606762 JCC: 0.593639



~! 118 !~
Accuracy: 4425 of 4974: 88.963 %
H: 0.692677 C: 0.554689 V: 0.616050 JCC: 0.604464



~! 120 !~
Accuracy: 4433 of 4974: 89.123 %
H: 0.693333 C: 0.556378 V: 0.617351 JCC: 0.604291



~! 122 !~
Accuracy: 4421 of 4974: 88.882 %
H: 0.689245 C: 0.552994 V: 0.613648 JCC: 0.604284



~! 124 !~
Accuracy: 4406 of 4974: 88.581 %
H: 0.685453 C: 0.549682 V: 0.610105 JCC: 0.602227



~! 126 !~
Accuracy: 4407 of 4974: 88.601 %
H: 0.687747 C: 0.550211 V: 0.611339 JCC: 0.604860


INCREMENT: (126)
SubClusters: 128
Accuracy: 4320 of 4974: 86.852 %
H: 0.687864 C: 0.182566 V: 0.288548 JCC: 0.039232


Final
Accuracy: 4407 of 4974: 88.601 %
H: 0.687747 C: 0.550211 V: 0.611339 JCC: 0.604860

Rows are labels, Columns are Clusters

       0     1     2    3    4
  0   34    19     0   38    0
  1   65    60     1   69  383
  2   30     0  1846    0    1
  3  106     1     1   57    0
  4  204  1356     5  618   80



Total Time: 27 m 9.522061 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.01
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
