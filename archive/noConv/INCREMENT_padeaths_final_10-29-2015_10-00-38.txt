./incDriver.py data/padeaths_final.csv -i pre -T -v 1


Using: data/padeaths_final.csv (4974)  --  (0.624798 s)
Initial Clustering: pre
Initial:  --  (0.165533 s)
Accuracy: 4110 of 4974: 82.630 %
H: 0.580722 C: 0.409397 V: 0.480237 JCC: 0.367172

Rows are labels, Columns are Clusters

        0     1    2    3    4    5
  0    43     0    2   46    0    0
  1   116     1  365   92    4    0
  2     1  1128    2   17  577  152
  3    62     0    4   94    5    0
  4  1168     0  697  388    5    5




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 6.990590 (1390)
		0: 6.278638 -- 1.340787  (24)
		1: 5.306838 -- 0.810968  (50)
		2: 6.367942 -- 1.583829  (19)
		3: 4.957726 -- 0.983988  (30)
		4: 6.174781 -- 0.934232  (56)
		5: 6.589325 -- 1.385220  (30)
		6: 5.920539 -- 2.125961  (9)
		7: 6.567970 -- 0.999936  (54)
		8: 6.612629 -- 1.042428  (44)
		9: 6.885159 -- 0.959690  (57)
		10: 7.434082 -- 1.452983  (28)
		11: 6.033438 -- 1.642548  (41)
		12: 5.646188 -- 1.418920  (17)
		13: 6.182988 -- 1.105277  (41)
		14: 7.382101 -- 1.216451  (51)
		15: 5.762526 -- 1.545209  (15)
		16: 6.154888 -- 1.106083  (36)
		17: 6.720705 -- 1.638890  (19)
		18: 6.439660 -- 1.002033  (51)
		19: 7.658732 -- 1.678430  (23)
		20: 7.128369 -- 1.657861  (26)
		21: 6.664756 -- 1.134256  (37)
		22: 7.020701 -- 1.113073  (44)
		23: 6.472895 -- 2.683516  (7)
		24: 7.033189 -- 1.395574  (27)
		25: 6.918580 -- 1.281531  (34)
		26: 7.326935 -- 1.197476  (44)
		27: 6.579981 -- 2.710793  (7)
		28: 6.656050 -- 1.410742  (24)
		29: 7.579976 -- 0.642960  (165)
		30: 8.171607 -- 1.584173  (29)
		31: 7.345847 -- 1.238597  (40)
		32: 7.650790 -- 1.135376  (49)
		33: 8.385742 -- 0.935721  (86)
		34: 8.217090 -- 1.715610  (27)
		35: 8.890865 -- 1.506463  (49)
	--> std: 1.497904 -- 0.441070

	1: 5.113596 (1129)
		36: 3.184644 -- 1.300173  (8)
		37: 3.690748 -- 0.661144  (39)
		38: 3.234517 -- 0.623686  (34)
		39: 2.851504 -- 1.014049  (9)
		40: 3.130806 -- 1.016458  (12)
		41: 2.549492 -- 1.476561  (4)
		42: 3.953317 -- 0.618088  (53)
		43: 4.468287 -- 1.191471  (17)
		44: 4.513166 -- 0.952016  (32)
		45: 4.500833 -- 0.941355  (35)
		46: 3.645371 -- 0.837356  (21)
		47: 4.069422 -- 0.947979  (23)
		48: 4.051761 -- 1.378959  (10)
		49: 4.641953 -- 0.561688  (84)
		50: 5.181541 -- 0.782182  (49)
		51: 4.527345 -- 1.045593  (20)
		52: 4.983198 -- 0.655431  (71)
		53: 5.000610 -- 0.640869  (70)
		54: 5.563711 -- 0.820610  (57)
		55: 5.022370 -- 1.015509  (37)
		56: 4.710054 -- 1.446011  (12)
		57: 5.598382 -- 0.738205  (63)
		58: 6.190104 -- 1.475429  (19)
		59: 5.872580 -- 1.325847  (21)
		60: 5.729006 -- 1.775051  (15)
		61: 5.562421 -- 0.983172  (38)
		62: 5.284247 -- 1.770510  (10)
		63: 5.186500 -- 2.117459  (7)
		64: 6.374901 -- 0.848037  (75)
		65: 5.115681 -- 1.071972  (63)
		66: 6.938167 -- 1.150656  (42)
		67: 7.244123 -- 2.238874  (23)
		68: 6.864692 -- 1.767639  (49)
		69: 7.106599 -- 3.101041  (7)
	--> std: 1.466513 -- 0.540298

	2: 6.897547 (1070)
		70: 6.056565 -- 1.528705  (20)
		71: 5.508192 -- 1.481861  (15)
		72: 5.242935 -- 1.336856  (17)
		73: 5.954196 -- 1.276576  (24)
		74: 5.257665 -- 2.366456  (6)
		75: 6.302508 -- 1.468792  (21)
		76: 5.833939 -- 1.139673  (34)
		77: 5.046600 -- 1.562900  (12)
		78: 5.303899 -- 0.842613  (68)
		79: 5.432975 -- 1.326260  (18)
		80: 5.552882 -- 1.432948  (18)
		81: 6.123476 -- 1.516418  (19)
		82: 6.614909 -- 1.416824  (25)
		83: 6.749584 -- 2.071571  (12)
		84: 7.672681 -- 4.430076  (4)
		85: 5.480304 -- 2.238524  (7)
		86: 6.182603 -- 1.404819  (21)
		87: 6.992106 -- 2.011000  (15)
		88: 6.764341 -- 1.513035  (29)
		89: 5.551159 -- 2.105238  (8)
		90: 6.638808 -- 0.969784  (54)
		91: 7.320716 -- 1.810451  (19)
		92: 7.190943 -- 0.911249  (81)
		93: 6.947950 -- 1.058338  (79)
		94: 7.065424 -- 0.885006  (70)
		95: 6.481185 -- 1.810986  (14)
		96: 7.100522 -- 1.779340  (18)
		97: 7.122693 -- 1.420374  (29)
		98: 7.785088 -- 2.308228  (13)
		99: 7.682720 -- 1.139088  (49)
		100: 8.025959 -- 0.809313  (110)
		101: 7.404657 -- 3.124042  (7)
		102: 6.311900 -- 1.440775  (29)
		103: 8.688472 -- 1.083151  (105)
	--> std: 1.642550 -- 0.698940

	3: 7.586960 (637)
		104: 7.486997 -- 8.568831  (633)
		105: 23.406077 -- 13.522767  (4)
	--> std: 8.700196 -- 2.476968

	4: 6.486207 (591)
		106: 3.816001 -- 0.649918  (47)
		107: 5.095997 -- 0.873323  (56)
		108: 6.124382 -- 1.385093  (37)
		109: 6.886143 -- 1.837393  (23)
		110: 6.112597 -- 1.132949  (31)
		111: 6.469685 -- 1.137042  (43)
		112: 5.900191 -- 1.546937  (16)
		113: 6.156641 -- 0.908561  (50)
		114: 6.871798 -- 1.426512  (27)
		115: 7.103472 -- 1.518666  (26)
		116: 6.010169 -- 3.019649  (5)
		117: 7.208786 -- 0.866752  (110)
		118: 7.334330 -- 2.264250  (15)
		119: 6.316892 -- 1.422192  (22)
		120: 7.779847 -- 1.323524  (41)
		121: 8.510600 -- 1.803075  (27)
		122: 8.181498 -- 2.255214  (15)
	--> std: 1.725679 -- 0.587089

	5: 6.929336 (157)
		123: 7.203831 -- 3.603129  (5)
		124: 5.385010 -- 2.059791  (8)
		125: 4.799666 -- 2.157709  (6)
		126: 6.161561 -- 1.523064  (21)
		127: 7.270220 -- 1.120937  (117)
	--> std: 1.586482 -- 0.843269

	Avg: 6.667373 -- 0.765806 
	Std: 2.769887 -- 2.653519 

Subclusters Formed: 128

Selecting Representatives:
Representatives:
[9, 3, 0, 1, 0, 0, 0, 14, 2, 12, 1, 2, 2, 2, 7, 1, 4, 4, 6, 11, 0, 7, 8, 0, 0, 0, 16, 2, 5, 101, 0, 10, 0, 20, 0, 7, 1, 0, 2, 2, 0, 0, 0, 0, 4, 7, 11, 0, 1, 2, 8, 6, 34, 0, 12, 2, 0, 14, 10, 2, 0, 0, 0, 3, 4, 2, 10, 6, 12, 3, 6, 1, 2, 0, 0, 0, 6, 0, 6, 0, 0, 0, 8, 1, 0, 0, 3, 0, 2, 0, 5, 0, 1, 18, 0, 2, 3, 1, 5, 5, 1, 3, 0, 25, 218, 2, 4, 19, 0, 0, 5, 0, 0, 6, 0, 3, 0, 7, 3, 3, 6, 3, 0, 0, 1, 0, 11, 32]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 2
	{'Type2': [22]}
	{'Type4': [105]}
Number of Queries: 2

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[105], [22]] 2

Connot Link Subcluster Constraints:
	[set([1]), set([0])] 2

Test All

Creating files for: _deploy
Train_data: (48, 403)
Data: (4974, 403)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip1"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "WrapperContrastiveLoss"
  bottom: "feat"
  bottom: "labels"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (4974, 403)
targets: (4974,)
K: 2
Reclustering

~! 2 !~
Accuracy: 3645 of 4974: 73.281 %
H: 0.268076 C: 0.489117 V: 0.346333 JCC: 0.475597



~! 3 !~
Accuracy: 3441 of 4974: 69.180 %
H: 0.191760 C: 0.344794 V: 0.246453 JCC: 0.421277



~! 4 !~
Accuracy: 3914 of 4974: 78.689 %
H: 0.394359 C: 0.669231 V: 0.496276 JCC: 0.590935



~! 5 !~
Accuracy: 4002 of 4974: 80.458 %
H: 0.466987 C: 0.501493 V: 0.483625 JCC: 0.531450



~! 6 !~
Accuracy: 4041 of 4974: 81.242 %
H: 0.455141 C: 0.770947 V: 0.572373 JCC: 0.642611



~! 7 !~
Accuracy: 3583 of 4974: 72.035 %
H: 0.312942 C: 0.335463 V: 0.323812 JCC: 0.366927



~! 8 !~
Accuracy: 3822 of 4974: 76.840 %
H: 0.388276 C: 0.411494 V: 0.399548 JCC: 0.439104



~! 9 !~
Accuracy: 4086 of 4974: 82.147 %
H: 0.560266 C: 0.595591 V: 0.577388 JCC: 0.582777



~! 10 !~
Accuracy: 3965 of 4974: 79.715 %
H: 0.474515 C: 0.505668 V: 0.489596 JCC: 0.525359



~! 11 !~
Accuracy: 3954 of 4974: 79.493 %
H: 0.460895 C: 0.493453 V: 0.476619 JCC: 0.534266



~! 12 !~
Accuracy: 4085 of 4974: 82.127 %
H: 0.512896 C: 0.548163 V: 0.529943 JCC: 0.559885



~! 13 !~
Accuracy: 4093 of 4974: 82.288 %
H: 0.548354 C: 0.623655 V: 0.583586 JCC: 0.653393



~! 14 !~
Accuracy: 4005 of 4974: 80.519 %
H: 0.482099 C: 0.417402 V: 0.447424 JCC: 0.465098



~! 15 !~
Accuracy: 4077 of 4974: 81.966 %
H: 0.531677 C: 0.569820 V: 0.550088 JCC: 0.573722



~! 16 !~
Accuracy: 4086 of 4974: 82.147 %
H: 0.541781 C: 0.578347 V: 0.559467 JCC: 0.574087



~! 17 !~
Accuracy: 4068 of 4974: 81.785 %
H: 0.550456 C: 0.475982 V: 0.510517 JCC: 0.512602



~! 18 !~
Accuracy: 4053 of 4974: 81.484 %
H: 0.550162 C: 0.483828 V: 0.514867 JCC: 0.520974



~! 19 !~
Accuracy: 4058 of 4974: 81.584 %
H: 0.523996 C: 0.573136 V: 0.547466 JCC: 0.594660



~! 20 !~
Accuracy: 4073 of 4974: 81.886 %
H: 0.522973 C: 0.565641 V: 0.543471 JCC: 0.581635



~! 21 !~
Accuracy: 4028 of 4974: 80.981 %
H: 0.538205 C: 0.588098 V: 0.562047 JCC: 0.614129



~! 22 !~
Accuracy: 4058 of 4974: 81.584 %
H: 0.511541 C: 0.554664 V: 0.532230 JCC: 0.569241



~! 23 !~
Accuracy: 4044 of 4974: 81.303 %
H: 0.507733 C: 0.565335 V: 0.534988 JCC: 0.586365



~! 24 !~
Accuracy: 4048 of 4974: 81.383 %
H: 0.578259 C: 0.519490 V: 0.547302 JCC: 0.544953



~! 25 !~
Accuracy: 4066 of 4974: 81.745 %
H: 0.580361 C: 0.536328 V: 0.557476 JCC: 0.607022



~! 26 !~
Accuracy: 4033 of 4974: 81.082 %
H: 0.586509 C: 0.534390 V: 0.559238 JCC: 0.571176



~! 27 !~
Accuracy: 4090 of 4974: 82.228 %
H: 0.596596 C: 0.570614 V: 0.583316 JCC: 0.637756



~! 28 !~
Accuracy: 4030 of 4974: 81.021 %
H: 0.571674 C: 0.523294 V: 0.546415 JCC: 0.555031



~! 29 !~
Accuracy: 4075 of 4974: 81.926 %
H: 0.573671 C: 0.530813 V: 0.551410 JCC: 0.577608



~! 30 !~
Accuracy: 4039 of 4974: 81.202 %
H: 0.611937 C: 0.570364 V: 0.590420 JCC: 0.624510



~! 31 !~
Accuracy: 4195 of 4974: 84.339 %
H: 0.624370 C: 0.599156 V: 0.611503 JCC: 0.671336



~! 32 !~
Accuracy: 4098 of 4974: 82.388 %
H: 0.599403 C: 0.554194 V: 0.575913 JCC: 0.613969



~! 33 !~
Accuracy: 4276 of 4974: 85.967 %
H: 0.633364 C: 0.608564 V: 0.620716 JCC: 0.684284



~! 34 !~
Accuracy: 4069 of 4974: 81.805 %
H: 0.607168 C: 0.568063 V: 0.586965 JCC: 0.630537



~! 35 !~
Accuracy: 4062 of 4974: 81.665 %
H: 0.597724 C: 0.540642 V: 0.567752 JCC: 0.584455



~! 36 !~
Accuracy: 4116 of 4974: 82.750 %
H: 0.616138 C: 0.580821 V: 0.597959 JCC: 0.645559



~! 37 !~
Accuracy: 4175 of 4974: 83.936 %
H: 0.620341 C: 0.591806 V: 0.605737 JCC: 0.664386



~! 38 !~
Accuracy: 4300 of 4974: 86.450 %
H: 0.641957 C: 0.630556 V: 0.636205 JCC: 0.699622



~! 39 !~
Accuracy: 4105 of 4974: 82.529 %
H: 0.618773 C: 0.580623 V: 0.599091 JCC: 0.639463



~! 40 !~
Accuracy: 4119 of 4974: 82.811 %
H: 0.588492 C: 0.555643 V: 0.571596 JCC: 0.630091



~! 41 !~
Accuracy: 4201 of 4974: 84.459 %
H: 0.592535 C: 0.566125 V: 0.579029 JCC: 0.638938



~! 42 !~
Accuracy: 4295 of 4974: 86.349 %
H: 0.636638 C: 0.506529 V: 0.564180 JCC: 0.559514



~! 43 !~
Accuracy: 4289 of 4974: 86.228 %
H: 0.646959 C: 0.623418 V: 0.634970 JCC: 0.691695



~! 44 !~
Accuracy: 4228 of 4974: 85.002 %
H: 0.617033 C: 0.595909 V: 0.606287 JCC: 0.671590



~! 45 !~
Accuracy: 4232 of 4974: 85.082 %
H: 0.631994 C: 0.615319 V: 0.623545 JCC: 0.689825



~! 46 !~
Accuracy: 4257 of 4974: 85.585 %
H: 0.645385 C: 0.623627 V: 0.634320 JCC: 0.690986



~! 47 !~
Accuracy: 4104 of 4974: 82.509 %
H: 0.613538 C: 0.582233 V: 0.597475 JCC: 0.640420



~! 48 !~
Accuracy: 4249 of 4974: 85.424 %
H: 0.622495 C: 0.597958 V: 0.609980 JCC: 0.667622



~! 49 !~
Accuracy: 4262 of 4974: 85.686 %
H: 0.595534 C: 0.566626 V: 0.580720 JCC: 0.642381



~! 50 !~
Accuracy: 4282 of 4974: 86.088 %
H: 0.630286 C: 0.627000 V: 0.628639 JCC: 0.702957



~! 51 !~
Accuracy: 4242 of 4974: 85.283 %
H: 0.619592 C: 0.609029 V: 0.614265 JCC: 0.682814



~! 52 !~
Accuracy: 4174 of 4974: 83.916 %
H: 0.620056 C: 0.609874 V: 0.614923 JCC: 0.676397



~! 53 !~
Accuracy: 4261 of 4974: 85.665 %
H: 0.642465 C: 0.628418 V: 0.635364 JCC: 0.699992



~! 54 !~
Accuracy: 4275 of 4974: 85.947 %
H: 0.619670 C: 0.608782 V: 0.614178 JCC: 0.682338



~! 55 !~
Accuracy: 4278 of 4974: 86.007 %
H: 0.644719 C: 0.638149 V: 0.641417 JCC: 0.709209



~! 56 !~
Accuracy: 4267 of 4974: 85.786 %
H: 0.637618 C: 0.632511 V: 0.635054 JCC: 0.696463



~! 57 !~
Accuracy: 4103 of 4974: 82.489 %
H: 0.580547 C: 0.511638 V: 0.543918 JCC: 0.532824



~! 58 !~
Accuracy: 4250 of 4974: 85.444 %
H: 0.622979 C: 0.608758 V: 0.615787 JCC: 0.679783



~! 59 !~
Accuracy: 4347 of 4974: 87.394 %
H: 0.660943 C: 0.624192 V: 0.642042 JCC: 0.673721



~! 60 !~
Accuracy: 4264 of 4974: 85.726 %
H: 0.641432 C: 0.637456 V: 0.639438 JCC: 0.704027



~! 61 !~
Accuracy: 4292 of 4974: 86.289 %
H: 0.638492 C: 0.641622 V: 0.640053 JCC: 0.708488



~! 62 !~
Accuracy: 4326 of 4974: 86.972 %
H: 0.650284 C: 0.652612 V: 0.651446 JCC: 0.721471



~! 63 !~
Accuracy: 4271 of 4974: 85.867 %
H: 0.636634 C: 0.635621 V: 0.636127 JCC: 0.704272



~! 64 !~
Accuracy: 4188 of 4974: 84.198 %
H: 0.628177 C: 0.614245 V: 0.621133 JCC: 0.677943



~! 65 !~
Accuracy: 4329 of 4974: 87.033 %
H: 0.658327 C: 0.534274 V: 0.589848 JCC: 0.588778



~! 66 !~
Accuracy: 4233 of 4974: 85.103 %
H: 0.630849 C: 0.620703 V: 0.625735 JCC: 0.685864



~! 67 !~
Accuracy: 4297 of 4974: 86.389 %
H: 0.643092 C: 0.641249 V: 0.642169 JCC: 0.707015



~! 68 !~
Accuracy: 4325 of 4974: 86.952 %
H: 0.654005 C: 0.531855 V: 0.586639 JCC: 0.584058



~! 69 !~
Accuracy: 4321 of 4974: 86.872 %
H: 0.651321 C: 0.528604 V: 0.583581 JCC: 0.578033



~! 70 !~
Accuracy: 4371 of 4974: 87.877 %
H: 0.667567 C: 0.530857 V: 0.591415 JCC: 0.582306



~! 71 !~
Accuracy: 4345 of 4974: 87.354 %
H: 0.657660 C: 0.528205 V: 0.585867 JCC: 0.584472



~! 72 !~
Accuracy: 4334 of 4974: 87.133 %
H: 0.660688 C: 0.527480 V: 0.586617 JCC: 0.582779



~! 73 !~
Accuracy: 4375 of 4974: 87.957 %
H: 0.679765 C: 0.543116 V: 0.603806 JCC: 0.589656



~! 74 !~
Accuracy: 4347 of 4974: 87.394 %
H: 0.660912 C: 0.531114 V: 0.588946 JCC: 0.590839



~! 75 !~
Accuracy: 4340 of 4974: 87.254 %
H: 0.659173 C: 0.527796 V: 0.586214 JCC: 0.583054



~! 76 !~
Accuracy: 4332 of 4974: 87.093 %
H: 0.655304 C: 0.521974 V: 0.581089 JCC: 0.569400



~! 77 !~
Accuracy: 4396 of 4974: 88.380 %
H: 0.690254 C: 0.555913 V: 0.615842 JCC: 0.605293



~! 78 !~
Accuracy: 4407 of 4974: 88.601 %
H: 0.688724 C: 0.556445 V: 0.615558 JCC: 0.607955



~! 79 !~
Accuracy: 4286 of 4974: 86.168 %
H: 0.641251 C: 0.515585 V: 0.571593 JCC: 0.579496



~! 80 !~
Accuracy: 4402 of 4974: 88.500 %
H: 0.689832 C: 0.563248 V: 0.620147 JCC: 0.618801



~! 81 !~
Accuracy: 4340 of 4974: 87.254 %
H: 0.661153 C: 0.537142 V: 0.592731 JCC: 0.600328



~! 82 !~
Accuracy: 4369 of 4974: 87.837 %
H: 0.669004 C: 0.549464 V: 0.603370 JCC: 0.622117



~! 83 !~
Accuracy: 4391 of 4974: 88.279 %
H: 0.682467 C: 0.558711 V: 0.614419 JCC: 0.614927



~! 84 !~
Accuracy: 4375 of 4974: 87.957 %
H: 0.674460 C: 0.554919 V: 0.608878 JCC: 0.621359



~! 85 !~
Accuracy: 4370 of 4974: 87.857 %
H: 0.674810 C: 0.543076 V: 0.601818 JCC: 0.599055



~! 86 !~
Accuracy: 4381 of 4974: 88.078 %
H: 0.683645 C: 0.556536 V: 0.613576 JCC: 0.617497



~! 87 !~
Accuracy: 4378 of 4974: 88.018 %
H: 0.674237 C: 0.548076 V: 0.604645 JCC: 0.603986



~! 88 !~
Accuracy: 4376 of 4974: 87.977 %
H: 0.679337 C: 0.555841 V: 0.611415 JCC: 0.616387



~! 89 !~
Accuracy: 4397 of 4974: 88.400 %
H: 0.687070 C: 0.563427 V: 0.619136 JCC: 0.628028



~! 90 !~
Accuracy: 4414 of 4974: 88.741 %
H: 0.687753 C: 0.559822 V: 0.617229 JCC: 0.614657



~! 91 !~
Accuracy: 4423 of 4974: 88.922 %
H: 0.689664 C: 0.567852 V: 0.622858 JCC: 0.629921



~! 92 !~
Accuracy: 4416 of 4974: 88.782 %
H: 0.690360 C: 0.564896 V: 0.621358 JCC: 0.622340



~! 93 !~
Accuracy: 4391 of 4974: 88.279 %
H: 0.684054 C: 0.560132 V: 0.615922 JCC: 0.623865



~! 94 !~
Accuracy: 4391 of 4974: 88.279 %
H: 0.681198 C: 0.565144 V: 0.617768 JCC: 0.638392



~! 95 !~
Accuracy: 4422 of 4974: 88.902 %
H: 0.693387 C: 0.568689 V: 0.624878 JCC: 0.627541



~! 96 !~
Accuracy: 4412 of 4974: 88.701 %
H: 0.687205 C: 0.570520 V: 0.623450 JCC: 0.639702



~! 97 !~
Accuracy: 4434 of 4974: 89.144 %
H: 0.701046 C: 0.577976 V: 0.633590 JCC: 0.637205



~! 98 !~
Accuracy: 4441 of 4974: 89.284 %
H: 0.703962 C: 0.583778 V: 0.638261 JCC: 0.644732



~! 99 !~
Accuracy: 4426 of 4974: 88.983 %
H: 0.697157 C: 0.575641 V: 0.630598 JCC: 0.637404



~! 100 !~
Accuracy: 4416 of 4974: 88.782 %
H: 0.691347 C: 0.578205 V: 0.629735 JCC: 0.648701



~! 101 !~
Accuracy: 4440 of 4974: 89.264 %
H: 0.704116 C: 0.576296 V: 0.633826 JCC: 0.629612



~! 102 !~
Accuracy: 4436 of 4974: 89.184 %
H: 0.701750 C: 0.575731 V: 0.632525 JCC: 0.632584



~! 103 !~
Accuracy: 4446 of 4974: 89.385 %
H: 0.703455 C: 0.576876 V: 0.633908 JCC: 0.632798



~! 104 !~
Accuracy: 4445 of 4974: 89.365 %
H: 0.705865 C: 0.578655 V: 0.635961 JCC: 0.633250



~! 105 !~
Accuracy: 4430 of 4974: 89.063 %
H: 0.695931 C: 0.568680 V: 0.625903 JCC: 0.625818



~! 106 !~
Accuracy: 4439 of 4974: 89.244 %
H: 0.701721 C: 0.579602 V: 0.634842 JCC: 0.640010



~! 107 !~
Accuracy: 4431 of 4974: 89.083 %
H: 0.697993 C: 0.572437 V: 0.629010 JCC: 0.629646



~! 108 !~
Accuracy: 4434 of 4974: 89.144 %
H: 0.698742 C: 0.575598 V: 0.631220 JCC: 0.635955



~! 109 !~
Accuracy: 4445 of 4974: 89.365 %
H: 0.703003 C: 0.577207 V: 0.633925 JCC: 0.635749



~! 110 !~
Accuracy: 4444 of 4974: 89.345 %
H: 0.704685 C: 0.572842 V: 0.631960 JCC: 0.622449



~! 111 !~
Accuracy: 4441 of 4974: 89.284 %
H: 0.702903 C: 0.578499 V: 0.634662 JCC: 0.634512



~! 112 !~
Accuracy: 4440 of 4974: 89.264 %
H: 0.701617 C: 0.576175 V: 0.632738 JCC: 0.630861



~! 113 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.702967 C: 0.578580 V: 0.634737 JCC: 0.638339



~! 114 !~
Accuracy: 4446 of 4974: 89.385 %
H: 0.706956 C: 0.580063 V: 0.637254 JCC: 0.635326



~! 115 !~
Accuracy: 4442 of 4974: 89.304 %
H: 0.701657 C: 0.576092 V: 0.632705 JCC: 0.635187



~! 116 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.708275 C: 0.580072 V: 0.637795 JCC: 0.629683



~! 117 !~
Accuracy: 4443 of 4974: 89.324 %
H: 0.701806 C: 0.578386 V: 0.634147 JCC: 0.639769



~! 118 !~
Accuracy: 4446 of 4974: 89.385 %
H: 0.707487 C: 0.577249 V: 0.635767 JCC: 0.627266



~! 119 !~
Accuracy: 4452 of 4974: 89.505 %
H: 0.709976 C: 0.576074 V: 0.636054 JCC: 0.623230



~! 120 !~
Accuracy: 4445 of 4974: 89.365 %
H: 0.698771 C: 0.575238 V: 0.631015 JCC: 0.635938



~! 121 !~
Accuracy: 4458 of 4974: 89.626 %
H: 0.712745 C: 0.580721 V: 0.639995 JCC: 0.630205



~! 122 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.707171 C: 0.580555 V: 0.637638 JCC: 0.638124



~! 123 !~
Accuracy: 4461 of 4974: 89.686 %
H: 0.708223 C: 0.580791 V: 0.638208 JCC: 0.634500



~! 124 !~
Accuracy: 4454 of 4974: 89.546 %
H: 0.708331 C: 0.580168 V: 0.637876 JCC: 0.630990



~! 125 !~
Accuracy: 4460 of 4974: 89.666 %
H: 0.709724 C: 0.579653 V: 0.638128 JCC: 0.631250



~! 126 !~
Accuracy: 4447 of 4974: 89.405 %
H: 0.702969 C: 0.570383 V: 0.629773 JCC: 0.620312



~! 127 !~
Accuracy: 4460 of 4974: 89.666 %
H: 0.711198 C: 0.579702 V: 0.638752 JCC: 0.631011


INCREMENT: (127)
SubClusters: 128
Accuracy: 4320 of 4974: 86.852 %
H: 0.687864 C: 0.182566 V: 0.288548 JCC: 0.039232


Final
Accuracy: 4460 of 4974: 89.666 %
H: 0.711198 C: 0.579702 V: 0.638752 JCC: 0.631011

Rows are labels, Columns are Clusters

        0    1    2     3    4
  0     0   32   36    23    0
  1     0   76   65    79  358
  2  1862    0   14     0    1
  3     0   43  121     1    0
  4     5  559  228  1453   18



Total Time: 38 m 19.821992 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.01
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
