./incDriver.py data/padeaths_final.csv -i pre -T -v 1


Using: data/padeaths_final.csv (4974)  --  (0.653617 s)
Initial Clustering: pre
Initial:  --  (0.166332 s)
Accuracy: 4110 of 4974: 82.630 %
H: 0.580722 C: 0.409397 V: 0.480237 JCC: 0.367172

Rows are labels, Columns are Clusters

        0     1    2    3    4    5
  0    43     0    2   46    0    0
  1   116     1  365   92    4    0
  2     1  1128    2   17  577  152
  3    62     0    4   94    5    0
  4  1168     0  697  388    5    5




Class: MergeINCREMENT
	RecursiveOPTICS
	MedoidSelector
	FarthestLabelFeedback
	OracleMatching
	Siamese


Siamese Setup:
	Batch Size: 10
	Output Size: 100
	Train Size: 100000

Testing INCREMENT
Subclustering:
Computing Distance
Running OPTICS: minPts = 5

Subcluster Breakdown:
	0: 6.990590 (1390)
		0: 6.278638 -- 1.340787  (24)
		1: 5.306838 -- 0.810968  (50)
		2: 6.367942 -- 1.583829  (19)
		3: 4.957726 -- 0.983988  (30)
		4: 6.174781 -- 0.934232  (56)
		5: 6.589325 -- 1.385220  (30)
		6: 5.920539 -- 2.125961  (9)
		7: 6.567970 -- 0.999936  (54)
		8: 6.612629 -- 1.042428  (44)
		9: 6.885159 -- 0.959690  (57)
		10: 7.434082 -- 1.452983  (28)
		11: 6.033438 -- 1.642548  (41)
		12: 5.646188 -- 1.418920  (17)
		13: 6.182988 -- 1.105277  (41)
		14: 7.382101 -- 1.216451  (51)
		15: 5.762526 -- 1.545209  (15)
		16: 6.154888 -- 1.106083  (36)
		17: 6.720705 -- 1.638890  (19)
		18: 6.439660 -- 1.002033  (51)
		19: 7.658732 -- 1.678430  (23)
		20: 7.128369 -- 1.657861  (26)
		21: 6.664756 -- 1.134256  (37)
		22: 7.020701 -- 1.113073  (44)
		23: 6.472895 -- 2.683516  (7)
		24: 7.033189 -- 1.395574  (27)
		25: 6.918580 -- 1.281531  (34)
		26: 7.326935 -- 1.197476  (44)
		27: 6.579981 -- 2.710793  (7)
		28: 6.656050 -- 1.410742  (24)
		29: 7.579976 -- 0.642960  (165)
		30: 8.171607 -- 1.584173  (29)
		31: 7.345847 -- 1.238597  (40)
		32: 7.650790 -- 1.135376  (49)
		33: 8.385742 -- 0.935721  (86)
		34: 8.217090 -- 1.715610  (27)
		35: 8.890865 -- 1.506463  (49)
	--> std: 1.497904 -- 0.441070

	1: 5.113596 (1129)
		36: 3.184644 -- 1.300173  (8)
		37: 3.690748 -- 0.661144  (39)
		38: 3.234517 -- 0.623686  (34)
		39: 2.851504 -- 1.014049  (9)
		40: 3.130806 -- 1.016458  (12)
		41: 2.549492 -- 1.476561  (4)
		42: 3.953317 -- 0.618088  (53)
		43: 4.468287 -- 1.191471  (17)
		44: 4.513166 -- 0.952016  (32)
		45: 4.500833 -- 0.941355  (35)
		46: 3.645371 -- 0.837356  (21)
		47: 4.069422 -- 0.947979  (23)
		48: 4.051761 -- 1.378959  (10)
		49: 4.641953 -- 0.561688  (84)
		50: 5.181541 -- 0.782182  (49)
		51: 4.527345 -- 1.045593  (20)
		52: 4.983198 -- 0.655431  (71)
		53: 5.000610 -- 0.640869  (70)
		54: 5.563711 -- 0.820610  (57)
		55: 5.022370 -- 1.015509  (37)
		56: 4.710054 -- 1.446011  (12)
		57: 5.598382 -- 0.738205  (63)
		58: 6.190104 -- 1.475429  (19)
		59: 5.872580 -- 1.325847  (21)
		60: 5.729006 -- 1.775051  (15)
		61: 5.562421 -- 0.983172  (38)
		62: 5.284247 -- 1.770510  (10)
		63: 5.186500 -- 2.117459  (7)
		64: 6.374901 -- 0.848037  (75)
		65: 5.115681 -- 1.071972  (63)
		66: 6.938167 -- 1.150656  (42)
		67: 7.244123 -- 2.238874  (23)
		68: 6.864692 -- 1.767639  (49)
		69: 7.106599 -- 3.101041  (7)
	--> std: 1.466513 -- 0.540298

	2: 6.897547 (1070)
		70: 6.056565 -- 1.528705  (20)
		71: 5.508192 -- 1.481861  (15)
		72: 5.242935 -- 1.336856  (17)
		73: 5.954196 -- 1.276576  (24)
		74: 5.257665 -- 2.366456  (6)
		75: 6.302508 -- 1.468792  (21)
		76: 5.833939 -- 1.139673  (34)
		77: 5.046600 -- 1.562900  (12)
		78: 5.303899 -- 0.842613  (68)
		79: 5.432975 -- 1.326260  (18)
		80: 5.552882 -- 1.432948  (18)
		81: 6.123476 -- 1.516418  (19)
		82: 6.614909 -- 1.416824  (25)
		83: 6.749584 -- 2.071571  (12)
		84: 7.672681 -- 4.430076  (4)
		85: 5.480304 -- 2.238524  (7)
		86: 6.182603 -- 1.404819  (21)
		87: 6.992106 -- 2.011000  (15)
		88: 6.764341 -- 1.513035  (29)
		89: 5.551159 -- 2.105238  (8)
		90: 6.638808 -- 0.969784  (54)
		91: 7.320716 -- 1.810451  (19)
		92: 7.190943 -- 0.911249  (81)
		93: 6.947950 -- 1.058338  (79)
		94: 7.065424 -- 0.885006  (70)
		95: 6.481185 -- 1.810986  (14)
		96: 7.100522 -- 1.779340  (18)
		97: 7.122693 -- 1.420374  (29)
		98: 7.785088 -- 2.308228  (13)
		99: 7.682720 -- 1.139088  (49)
		100: 8.025959 -- 0.809313  (110)
		101: 7.404657 -- 3.124042  (7)
		102: 6.311900 -- 1.440775  (29)
		103: 8.688472 -- 1.083151  (105)
	--> std: 1.642550 -- 0.698940

	3: 7.586960 (637)
		104: 7.486997 -- 8.568831  (633)
		105: 23.406077 -- 13.522767  (4)
	--> std: 8.700196 -- 2.476968

	4: 6.486207 (591)
		106: 3.816001 -- 0.649918  (47)
		107: 5.095997 -- 0.873323  (56)
		108: 6.124382 -- 1.385093  (37)
		109: 6.886143 -- 1.837393  (23)
		110: 6.112597 -- 1.132949  (31)
		111: 6.469685 -- 1.137042  (43)
		112: 5.900191 -- 1.546937  (16)
		113: 6.156641 -- 0.908561  (50)
		114: 6.871798 -- 1.426512  (27)
		115: 7.103472 -- 1.518666  (26)
		116: 6.010169 -- 3.019649  (5)
		117: 7.208786 -- 0.866752  (110)
		118: 7.334330 -- 2.264250  (15)
		119: 6.316892 -- 1.422192  (22)
		120: 7.779847 -- 1.323524  (41)
		121: 8.510600 -- 1.803075  (27)
		122: 8.181498 -- 2.255214  (15)
	--> std: 1.725679 -- 0.587089

	5: 6.929336 (157)
		123: 7.203831 -- 3.603129  (5)
		124: 5.385010 -- 2.059791  (8)
		125: 4.799666 -- 2.157709  (6)
		126: 6.161561 -- 1.523064  (21)
		127: 7.270220 -- 1.120937  (117)
	--> std: 1.586482 -- 0.843269

	Avg: 6.667373 -- 0.765806 
	Std: 2.769887 -- 2.653519 

Subclusters Formed: 128

Selecting Representatives:
Representatives:
[9, 3, 0, 1, 0, 0, 0, 14, 2, 12, 1, 2, 2, 2, 7, 1, 4, 4, 6, 11, 0, 7, 8, 0, 0, 0, 16, 2, 5, 101, 0, 10, 0, 20, 0, 7, 1, 0, 2, 2, 0, 0, 0, 0, 4, 7, 11, 0, 1, 2, 8, 6, 34, 0, 12, 2, 0, 14, 10, 2, 0, 0, 0, 3, 4, 2, 10, 6, 12, 3, 6, 1, 2, 0, 0, 0, 6, 0, 6, 0, 0, 0, 8, 1, 0, 0, 3, 0, 2, 0, 5, 0, 1, 18, 0, 2, 3, 1, 5, 5, 1, 3, 0, 25, 218, 2, 4, 19, 0, 0, 5, 0, 0, 6, 0, 3, 0, 7, 3, 3, 6, 3, 0, 0, 1, 0, 11, 32]


Generating Feedback:
Farthest First
Computing pairwise distances between representatives.
Beginning Queries
Feedback: 2
	{'Type4': [101]}
	{'Type4': [105]}
Number of Queries: 2

Merging Subclusters:
Generating Data

Train All

Merged Feedback:
	[[105, 101]] 1

Connot Link Subcluster Constraints:
	[set([])] 1

Test All

Creating files for: _deploy
Train_data: (11, 403)
Data: (4974, 403)
Creating files for: _train
Network:
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  hdf5_data_param {
    source: "_train.txt"
    batch_size: 10
    shuffle: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "data"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "gaussian"
      std: 0.1
    }
  }
}
layer {
  name: "s1"
  type: "Sigmoid"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip1"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "WrapperContrastiveLoss"
  bottom: "feat"
  bottom: "labels"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}


Training siamese network
data (4974, 403)
targets: (4974,)
K: 1
Reclustering

~! 2 !~
Accuracy: 2263 of 4974: 45.497 %
H: 0.000000 C: 1.000000 V: 0.000000 JCC: 0.364207



~! 3 !~
Accuracy: 3763 of 4974: 75.653 %
H: 0.312764 C: 0.421130 V: 0.358946 JCC: 0.513793



~! 4 !~
Accuracy: 3909 of 4974: 78.589 %
H: 0.406379 C: 0.436670 V: 0.420980 JCC: 0.471261



~! 5 !~
Accuracy: 3402 of 4974: 68.396 %
H: 0.178453 C: 0.303187 V: 0.224668 JCC: 0.414865



~! 6 !~
Accuracy: 3832 of 4974: 77.041 %
H: 0.358433 C: 0.643475 V: 0.460407 JCC: 0.537984



~! 7 !~
Accuracy: 4003 of 4974: 80.478 %
H: 0.437392 C: 0.741477 V: 0.550216 JCC: 0.623578



~! 8 !~
Accuracy: 4045 of 4974: 81.323 %
H: 0.462964 C: 0.786883 V: 0.582949 JCC: 0.643266



~! 9 !~
Accuracy: 3986 of 4974: 80.137 %
H: 0.467086 C: 0.414184 V: 0.439047 JCC: 0.397106



~! 10 !~
Accuracy: 4034 of 4974: 81.102 %
H: 0.507868 C: 0.543051 V: 0.524871 JCC: 0.560526



~! 11 !~
Accuracy: 4061 of 4974: 81.645 %
H: 0.527237 C: 0.568103 V: 0.546908 JCC: 0.584991



~! 12 !~
Accuracy: 4046 of 4974: 81.343 %
H: 0.527364 C: 0.564995 V: 0.545531 JCC: 0.573380



~! 13 !~
Accuracy: 4033 of 4974: 81.082 %
H: 0.492690 C: 0.525414 V: 0.508526 JCC: 0.546711



~! 14 !~
Accuracy: 4063 of 4974: 81.685 %
H: 0.503805 C: 0.537063 V: 0.519902 JCC: 0.540250



~! 15 !~
Accuracy: 4053 of 4974: 81.484 %
H: 0.494147 C: 0.526570 V: 0.509844 JCC: 0.535547



~! 16 !~
Accuracy: 4069 of 4974: 81.805 %
H: 0.495765 C: 0.536480 V: 0.515320 JCC: 0.552228



~! 17 !~
Accuracy: 4069 of 4974: 81.805 %
H: 0.532485 C: 0.568750 V: 0.550021 JCC: 0.568662



~! 18 !~
Accuracy: 4042 of 4974: 81.263 %
H: 0.513356 C: 0.449735 V: 0.479444 JCC: 0.446573



~! 19 !~
Accuracy: 4026 of 4974: 80.941 %
H: 0.518219 C: 0.554498 V: 0.535745 JCC: 0.570684



~! 20 !~
Accuracy: 4065 of 4974: 81.725 %
H: 0.522409 C: 0.566664 V: 0.543638 JCC: 0.590357



~! 21 !~
Accuracy: 4050 of 4974: 81.423 %
H: 0.548534 C: 0.488695 V: 0.516888 JCC: 0.537258



~! 22 !~
Accuracy: 4046 of 4974: 81.343 %
H: 0.504653 C: 0.543032 V: 0.523140 JCC: 0.554482



~! 23 !~
Accuracy: 4060 of 4974: 81.624 %
H: 0.515407 C: 0.554800 V: 0.534378 JCC: 0.560064



~! 24 !~
Accuracy: 4192 of 4974: 84.278 %
H: 0.565199 C: 0.518072 V: 0.540611 JCC: 0.580891



~! 25 !~
Accuracy: 4034 of 4974: 81.102 %
H: 0.561240 C: 0.521580 V: 0.540684 JCC: 0.560527



~! 26 !~
Accuracy: 4122 of 4974: 82.871 %
H: 0.560806 C: 0.500787 V: 0.529100 JCC: 0.551959



~! 27 !~
Accuracy: 4089 of 4974: 82.207 %
H: 0.602079 C: 0.566945 V: 0.583984 JCC: 0.636847



~! 28 !~
Accuracy: 4043 of 4974: 81.283 %
H: 0.568688 C: 0.518638 V: 0.542511 JCC: 0.537067



~! 29 !~
Accuracy: 4105 of 4974: 82.529 %
H: 0.603288 C: 0.570682 V: 0.586532 JCC: 0.641376



~! 30 !~
Accuracy: 4166 of 4974: 83.756 %
H: 0.613247 C: 0.567861 V: 0.589682 JCC: 0.625072



~! 31 !~
Accuracy: 4028 of 4974: 80.981 %
H: 0.584646 C: 0.524857 V: 0.553140 JCC: 0.580962



~! 32 !~
Accuracy: 4054 of 4974: 81.504 %
H: 0.590915 C: 0.548107 V: 0.568707 JCC: 0.617073



~! 33 !~
Accuracy: 4172 of 4974: 83.876 %
H: 0.565212 C: 0.517287 V: 0.540189 JCC: 0.588748



~! 34 !~
Accuracy: 4099 of 4974: 82.409 %
H: 0.607007 C: 0.566373 V: 0.585987 JCC: 0.622280



~! 35 !~
Accuracy: 4150 of 4974: 83.434 %
H: 0.614179 C: 0.574042 V: 0.593433 JCC: 0.635472



~! 36 !~
Accuracy: 4046 of 4974: 81.343 %
H: 0.609786 C: 0.566861 V: 0.587541 JCC: 0.625732



~! 37 !~
Accuracy: 4204 of 4974: 84.520 %
H: 0.617449 C: 0.584599 V: 0.600575 JCC: 0.656660



~! 38 !~
Accuracy: 4205 of 4974: 84.540 %
H: 0.613924 C: 0.595145 V: 0.604389 JCC: 0.668572



~! 39 !~
Accuracy: 4181 of 4974: 84.057 %
H: 0.619156 C: 0.595462 V: 0.607078 JCC: 0.668545



~! 40 !~
Accuracy: 4094 of 4974: 82.308 %
H: 0.595734 C: 0.568780 V: 0.581945 JCC: 0.631233



~! 41 !~
Accuracy: 4138 of 4974: 83.193 %
H: 0.619961 C: 0.585193 V: 0.602075 JCC: 0.647600



~! 42 !~
Accuracy: 4250 of 4974: 85.444 %
H: 0.623127 C: 0.589344 V: 0.605765 JCC: 0.658492



~! 43 !~
Accuracy: 4234 of 4974: 85.123 %
H: 0.626599 C: 0.614662 V: 0.620573 JCC: 0.687527



~! 44 !~
Accuracy: 4233 of 4974: 85.103 %
H: 0.633167 C: 0.615026 V: 0.623965 JCC: 0.682079



~! 45 !~
Accuracy: 4286 of 4974: 86.168 %
H: 0.653389 C: 0.516105 V: 0.576689 JCC: 0.560612



~! 46 !~
Accuracy: 4162 of 4974: 83.675 %
H: 0.612947 C: 0.583560 V: 0.597893 JCC: 0.648472



~! 47 !~
Accuracy: 4232 of 4974: 85.082 %
H: 0.625486 C: 0.610366 V: 0.617834 JCC: 0.685912



~! 48 !~
Accuracy: 4237 of 4974: 85.183 %
H: 0.621553 C: 0.602104 V: 0.611674 JCC: 0.677316



~! 49 !~
Accuracy: 4219 of 4974: 84.821 %
H: 0.606785 C: 0.603582 V: 0.605179 JCC: 0.673692



~! 50 !~
Accuracy: 4257 of 4974: 85.585 %
H: 0.630894 C: 0.623622 V: 0.627237 JCC: 0.697805



~! 51 !~
Accuracy: 4262 of 4974: 85.686 %
H: 0.627323 C: 0.604347 V: 0.615621 JCC: 0.676948



~! 52 !~
Accuracy: 4255 of 4974: 85.545 %
H: 0.638142 C: 0.623841 V: 0.630911 JCC: 0.693841



~! 53 !~
Accuracy: 4236 of 4974: 85.163 %
H: 0.631250 C: 0.622791 V: 0.626992 JCC: 0.690568



~! 54 !~
Accuracy: 4310 of 4974: 86.651 %
H: 0.615251 C: 0.606955 V: 0.611075 JCC: 0.685795



~! 55 !~
Accuracy: 4301 of 4974: 86.470 %
H: 0.650862 C: 0.606528 V: 0.627913 JCC: 0.653919



~! 56 !~
Accuracy: 4268 of 4974: 85.806 %
H: 0.629977 C: 0.629974 V: 0.629976 JCC: 0.699430



~! 57 !~
Accuracy: 4296 of 4974: 86.369 %
H: 0.654605 C: 0.525608 V: 0.583057 JCC: 0.571453



~! 58 !~
Accuracy: 4283 of 4974: 86.108 %
H: 0.642716 C: 0.636502 V: 0.639594 JCC: 0.704734



~! 59 !~
Accuracy: 4295 of 4974: 86.349 %
H: 0.643593 C: 0.597674 V: 0.619784 JCC: 0.651991



~! 60 !~
Accuracy: 4274 of 4974: 85.927 %
H: 0.634000 C: 0.629020 V: 0.631500 JCC: 0.699623



~! 61 !~
Accuracy: 4223 of 4974: 84.901 %
H: 0.629570 C: 0.620808 V: 0.625158 JCC: 0.688745



~! 62 !~
Accuracy: 4348 of 4974: 87.415 %
H: 0.667468 C: 0.627464 V: 0.646849 JCC: 0.677351



~! 63 !~
Accuracy: 4282 of 4974: 86.088 %
H: 0.643560 C: 0.636304 V: 0.639912 JCC: 0.703706



~! 64 !~
Accuracy: 4101 of 4974: 82.449 %
H: 0.578544 C: 0.511368 V: 0.542886 JCC: 0.535655



~! 65 !~
Accuracy: 4315 of 4974: 86.751 %
H: 0.649555 C: 0.517053 V: 0.575779 JCC: 0.572212



~! 66 !~
Accuracy: 4305 of 4974: 86.550 %
H: 0.637642 C: 0.516599 V: 0.570774 JCC: 0.563631



~! 67 !~
Accuracy: 4397 of 4974: 88.400 %
H: 0.656612 C: 0.638353 V: 0.647353 JCC: 0.709774



~! 68 !~
Accuracy: 4413 of 4974: 88.721 %
H: 0.679988 C: 0.550939 V: 0.608699 JCC: 0.605506



~! 69 !~
Accuracy: 4380 of 4974: 88.058 %
H: 0.676854 C: 0.541405 V: 0.601600 JCC: 0.585556



~! 70 !~
Accuracy: 4350 of 4974: 87.455 %
H: 0.651783 C: 0.529567 V: 0.584353 JCC: 0.574458



~! 71 !~
Accuracy: 4371 of 4974: 87.877 %
H: 0.668843 C: 0.539468 V: 0.597229 JCC: 0.591698



~! 72 !~
Accuracy: 4376 of 4974: 87.977 %
H: 0.674155 C: 0.543652 V: 0.601911 JCC: 0.597421



~! 73 !~
Accuracy: 4398 of 4974: 88.420 %
H: 0.685984 C: 0.546531 V: 0.608368 JCC: 0.586303



~! 74 !~
Accuracy: 4361 of 4974: 87.676 %
H: 0.677325 C: 0.543817 V: 0.603273 JCC: 0.597440



~! 75 !~
Accuracy: 4328 of 4974: 87.012 %
H: 0.658332 C: 0.526624 V: 0.585158 JCC: 0.583812



~! 76 !~
Accuracy: 4300 of 4974: 86.450 %
H: 0.653648 C: 0.527683 V: 0.583949 JCC: 0.599779



~! 77 !~
Accuracy: 4347 of 4974: 87.394 %
H: 0.663439 C: 0.530713 V: 0.589700 JCC: 0.582371



~! 78 !~
Accuracy: 4356 of 4974: 87.575 %
H: 0.666281 C: 0.537929 V: 0.595265 JCC: 0.598213



~! 79 !~
Accuracy: 4355 of 4974: 87.555 %
H: 0.670795 C: 0.541813 V: 0.599444 JCC: 0.599157



~! 80 !~
Accuracy: 4337 of 4974: 87.193 %
H: 0.660322 C: 0.539009 V: 0.593530 JCC: 0.607219



~! 81 !~
Accuracy: 4341 of 4974: 87.274 %
H: 0.666749 C: 0.543479 V: 0.598836 JCC: 0.613715



~! 82 !~
Accuracy: 4346 of 4974: 87.374 %
H: 0.661946 C: 0.530984 V: 0.589276 JCC: 0.584916



~! 83 !~
Accuracy: 4335 of 4974: 87.153 %
H: 0.660740 C: 0.536596 V: 0.592232 JCC: 0.606042



~! 84 !~
Accuracy: 4360 of 4974: 87.656 %
H: 0.669257 C: 0.546755 V: 0.601836 JCC: 0.610732



~! 85 !~
Accuracy: 4361 of 4974: 87.676 %
H: 0.673678 C: 0.553253 V: 0.607555 JCC: 0.619144



~! 86 !~
Accuracy: 4389 of 4974: 88.239 %
H: 0.683257 C: 0.559815 V: 0.615407 JCC: 0.622879



~! 87 !~
Accuracy: 4379 of 4974: 88.038 %
H: 0.679172 C: 0.558798 V: 0.613133 JCC: 0.624975



~! 88 !~
Accuracy: 4387 of 4974: 88.199 %
H: 0.681898 C: 0.557447 V: 0.613424 JCC: 0.615243



~! 89 !~
Accuracy: 4350 of 4974: 87.455 %
H: 0.663613 C: 0.546217 V: 0.599219 JCC: 0.621671



~! 90 !~
Accuracy: 4344 of 4974: 87.334 %
H: 0.671162 C: 0.547224 V: 0.602890 JCC: 0.609177



~! 91 !~
Accuracy: 4412 of 4974: 88.701 %
H: 0.691245 C: 0.574867 V: 0.627707 JCC: 0.643715



~! 92 !~
Accuracy: 4390 of 4974: 88.259 %
H: 0.685584 C: 0.558979 V: 0.615842 JCC: 0.618387



~! 93 !~
Accuracy: 4372 of 4974: 87.897 %
H: 0.678208 C: 0.556716 V: 0.611486 JCC: 0.624547



~! 94 !~
Accuracy: 4377 of 4974: 87.998 %
H: 0.677978 C: 0.560324 V: 0.613562 JCC: 0.632420



~! 95 !~
Accuracy: 4432 of 4974: 89.103 %
H: 0.699096 C: 0.573637 V: 0.630183 JCC: 0.631522



~! 96 !~
Accuracy: 4407 of 4974: 88.601 %
H: 0.686292 C: 0.568546 V: 0.621895 JCC: 0.637718



~! 97 !~
Accuracy: 4426 of 4974: 88.983 %
H: 0.694232 C: 0.576172 V: 0.629716 JCC: 0.641236



~! 98 !~
Accuracy: 4429 of 4974: 89.043 %
H: 0.695471 C: 0.575956 V: 0.630096 JCC: 0.640117



~! 99 !~
Accuracy: 4431 of 4974: 89.083 %
H: 0.698909 C: 0.575710 V: 0.631356 JCC: 0.634324



~! 100 !~
Accuracy: 4428 of 4974: 89.023 %
H: 0.699072 C: 0.577522 V: 0.632511 JCC: 0.635872



~! 101 !~
Accuracy: 4423 of 4974: 88.922 %
H: 0.698675 C: 0.580984 V: 0.634417 JCC: 0.648097



~! 102 !~
Accuracy: 4431 of 4974: 89.083 %
H: 0.701419 C: 0.578988 V: 0.634350 JCC: 0.639929



~! 103 !~
Accuracy: 4443 of 4974: 89.324 %
H: 0.706094 C: 0.587155 V: 0.641155 JCC: 0.652685



~! 104 !~
Accuracy: 4436 of 4974: 89.184 %
H: 0.702959 C: 0.580130 V: 0.635665 JCC: 0.639515



~! 105 !~
Accuracy: 4435 of 4974: 89.164 %
H: 0.701560 C: 0.575704 V: 0.632431 JCC: 0.632483



~! 106 !~
Accuracy: 4434 of 4974: 89.144 %
H: 0.699397 C: 0.573363 V: 0.630140 JCC: 0.627975



~! 107 !~
Accuracy: 4445 of 4974: 89.365 %
H: 0.706323 C: 0.576762 V: 0.635001 JCC: 0.629480



~! 108 !~
Accuracy: 4444 of 4974: 89.345 %
H: 0.699508 C: 0.574722 V: 0.631005 JCC: 0.636220



~! 109 !~
Accuracy: 4425 of 4974: 88.963 %
H: 0.693741 C: 0.569107 V: 0.625274 JCC: 0.625035



~! 110 !~
Accuracy: 4441 of 4974: 89.284 %
H: 0.705990 C: 0.578151 V: 0.635707 JCC: 0.631595



~! 111 !~
Accuracy: 4447 of 4974: 89.405 %
H: 0.703500 C: 0.577628 V: 0.634381 JCC: 0.633007



~! 112 !~
Accuracy: 4434 of 4974: 89.144 %
H: 0.699314 C: 0.577221 V: 0.632429 JCC: 0.638048



~! 113 !~
Accuracy: 4441 of 4974: 89.284 %
H: 0.702722 C: 0.582694 V: 0.637104 JCC: 0.646424



~! 114 !~
Accuracy: 4440 of 4974: 89.264 %
H: 0.700309 C: 0.575260 V: 0.631655 JCC: 0.633208



~! 115 !~
Accuracy: 4452 of 4974: 89.505 %
H: 0.705749 C: 0.578398 V: 0.635759 JCC: 0.633897



~! 116 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.708151 C: 0.584752 V: 0.640563 JCC: 0.640034



~! 117 !~
Accuracy: 4459 of 4974: 89.646 %
H: 0.711403 C: 0.586816 V: 0.643131 JCC: 0.641614



~! 118 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.707087 C: 0.580031 V: 0.637288 JCC: 0.639792



~! 119 !~
Accuracy: 4452 of 4974: 89.505 %
H: 0.709058 C: 0.581352 V: 0.638886 JCC: 0.634461



~! 120 !~
Accuracy: 4450 of 4974: 89.465 %
H: 0.704013 C: 0.573077 V: 0.631833 JCC: 0.624279



~! 121 !~
Accuracy: 4456 of 4974: 89.586 %
H: 0.708826 C: 0.584101 V: 0.640448 JCC: 0.641066



~! 122 !~
Accuracy: 4447 of 4974: 89.405 %
H: 0.706086 C: 0.580038 V: 0.636885 JCC: 0.635903



~! 123 !~
Accuracy: 4455 of 4974: 89.566 %
H: 0.706850 C: 0.582331 V: 0.638577 JCC: 0.641472



~! 124 !~
Accuracy: 4442 of 4974: 89.304 %
H: 0.698714 C: 0.572593 V: 0.629397 JCC: 0.633226



~! 125 !~
Accuracy: 4463 of 4974: 89.727 %
H: 0.710931 C: 0.591675 V: 0.645844 JCC: 0.654849



~! 126 !~
Accuracy: 4451 of 4974: 89.485 %
H: 0.706114 C: 0.575198 V: 0.633968 JCC: 0.626939



~! 127 !~
Accuracy: 4445 of 4974: 89.365 %
H: 0.697687 C: 0.569819 V: 0.627303 JCC: 0.626021


INCREMENT: (127)
SubClusters: 128
Accuracy: 4320 of 4974: 86.852 %
H: 0.687864 C: 0.182566 V: 0.288548 JCC: 0.039232


Final
Accuracy: 4445 of 4974: 89.365 %
H: 0.697687 C: 0.569819 V: 0.627303 JCC: 0.626021

Rows are labels, Columns are Clusters

        0     1    2    3    4
  0    23     0   35    0   33
  1    92     3   67  352   64
  2     0  1859   16    1    1
  3     2     0  115    0   48
  4  1454     5  226   24  554



Total Time: 38 m 18.772671 s




Solver:
net: "_TRAIN_NET.prototxt"
base_lr: 0.1
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.1
max_iter: 10000
display: 1000
weight_decay: 0.000000
solver_mode: GPU
